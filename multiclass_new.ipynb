{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ds3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from class_dataset import ChestDataset\n",
    "import pandas as pd\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications\n",
    "from keras.applications import DenseNet121\n",
    "from keras import models\n",
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13405978113956095677\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15607572071\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7595574869225846037\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0\"\n",
      "]\n",
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "# os.system('sudo chown -R ds:ds /data')\n",
    "# os.mkdir('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds/notebooks/class_dataset.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.reader['exists'] = self.exists\n"
     ]
    }
   ],
   "source": [
    "# CHOOSE now your model name \n",
    "model_name = 'densechest_multiclass'\n",
    "\n",
    "csvfile = 'data_kaggle/Data_Entry_2017.csv'\n",
    "df = pd.read_csv(csvfile)\n",
    "\n",
    "data_dir = '/data/xray_chest_final/'\n",
    "\n",
    "ChestDataset(data_dir,df).reset_folder()\n",
    "\n",
    "df_uni = ChestDataset(data_dir,df[~df['Finding Labels'].str.contains('\\|')]).reader\n",
    "df_uni = df_uni[df_uni.exists == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChestDataset(data_dir,df_uni)\n",
    "\n",
    "train_list = [el[len(data_dir):] for i,el in enumerate(dataset.image_path) if not i%5 == 0]\n",
    "test_list = [el[len(data_dir):] for i,el in enumerate(dataset.image_path) if i%5 == 0]\n",
    "class_weights = dict(df_uni.groupby('Finding Labels').count().exists/(len(df_uni)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds/notebooks/class_dataset.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.reader['exists'] = self.exists\n"
     ]
    }
   ],
   "source": [
    "with open('output/{}_train_list.txt'.format(model_name), 'w') as f:\n",
    "    for item in train_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open('output/{}_test_list.txt'.format(model_name), 'w') as f:\n",
    "    for item in test_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "train_dt,test_dt = dataset.train_test(train_list,test_list)\n",
    "train_dt.create_tree()\n",
    "test_dt.create_tree()\n",
    "\n",
    "train_files = train_dt.image_path\n",
    "test_files = test_dt.image_path\n",
    "train_folder = train_dt.dir\n",
    "test_folder = test_dt.dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 8, 8, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                983055    \n",
      "=================================================================\n",
      "Total params: 8,020,559\n",
      "Trainable params: 7,936,911\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ADD YOUR MODEL\n",
    "img_width,img_height = 256,256\n",
    "densenet = DenseNet121(weights='imagenet', include_top=False,input_shape = (img_width, img_height, 3))\n",
    "\n",
    "# # Freeze some layers\n",
    "# for layer in densenet.layers[:100]:\n",
    "#     layer.trainable = False\n",
    "    \n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(densenet)\n",
    "\n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(72))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.248))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19250 images belonging to 15 classes.\n",
      "Found 4813 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  rotation_range=20,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_batchsize = 10\n",
    "val_batchsize = 10\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_folder,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=train_batchsize,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    test_folder,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=val_batchsize,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "class_weights = {train_generator.class_indices[k]:v for k,v in class_weights.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 702/1925 [=========>....................] - ETA: 6:10 - loss: 0.2119 - acc: 0.6916"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='output/logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "filepath = \"output/checkpoint_{}.hdf5\".format(model_name)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=5,\n",
    "    class_weight=class_weights,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "fig.savefig('output/history_{}.png'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"output/{}.json\".format(model_name), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"output/{}.h5\".format(model_name))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_generator(validation_generator,\n",
    "                                     steps=len(validation_generator),\n",
    "                                     pickle_safe=True,\n",
    "                                     verbose=1)\n",
    "\n",
    "\n",
    "preds = np.argmax(prediction,axis=1)\n",
    "\n",
    "y_true = np.zeros((preds.shape[0],validation_generator.num_classes))\n",
    "y_true[np.arange(preds.shape[0]), validation_generator.classes] = 1\n",
    "inv_map = {v:k for k,v in validation_generator.class_indices.items()}\n",
    "pred_cat = [inv_map[i] for i in preds]\n",
    "\n",
    "report = classification_report(validation_generator.classes,preds)\n",
    "np.save('output/report_{}.npy'.format(model_name),report)\n",
    "print(report)\n",
    "print('Accuracy score: ',accuracy_score(validation_generator.classes,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator,\n",
    "                                 steps=len(validation_generator),\n",
    "                                 pickle_safe=True)\n",
    "print('Accuracy Keras: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auc scores\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(validation_generator.num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], prediction[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "for i in range(validation_generator.num_classes):\n",
    "    plt.plot(fpr[i], tpr[i],\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(inv_map[i], roc_auc[i]))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "fig.savefig('output/roc_curve_{}.png'.format(model_name))\n",
    "\n",
    "print('End Of Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
