{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T18:45:41.818866Z",
     "start_time": "2019-01-26T18:45:39.350277Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from class_dataset import ChestDataset\n",
    "import pandas as pd\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications\n",
    "from keras.applications import DenseNet121\n",
    "from keras import models\n",
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T18:45:42.113220Z",
     "start_time": "2019-01-26T18:45:40.545Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(device_lib.list_local_devices())\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "# os.system('sudo chown -R ds:ds /data')\n",
    "# os.mkdir('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T18:46:36.366164Z",
     "start_time": "2019-01-26T18:46:35.598651Z"
    }
   },
   "outputs": [],
   "source": [
    "# CHOOSE now your model name \n",
    "model_name = 'densechest_multilabel'\n",
    "\n",
    "csvfile = 'data_kaggle/Data_Entry_2017.csv'\n",
    "df = pd.read_csv(csvfile)\n",
    "\n",
    "data_dir = '/data/xray_chest_final/'\n",
    "\n",
    "# ChestDataset(data_dir,df).reset_folder()\n",
    "\n",
    "df = ChestDataset(data_dir,df).reader\n",
    "df = df[df.exists == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T18:46:37.039332Z",
     "start_time": "2019-01-26T18:46:36.903706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            43851\n",
       "Infiltration                 7537\n",
       "Atelectasis                  3083\n",
       "Effusion                     3019\n",
       "Nodule                       1996\n",
       "Mass                         1715\n",
       "Pneumothorax                 1670\n",
       "Effusion|Infiltration        1309\n",
       "Atelectasis|Infiltration     1025\n",
       "Consolidation                 990\n",
       "Atelectasis|Effusion          872\n",
       "Pleural_Thickening            801\n",
       "Cardiomegaly                  698\n",
       "Emphysema                     672\n",
       "Name: Finding Labels, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Finding Labels'] = df['Finding Labels'].replace('No Finding','')\n",
    "df = df[df['Finding Labels'].isin(list(df['Finding Labels'].value_counts()[:14].index.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T18:46:44.804930Z",
     "start_time": "2019-01-26T18:46:37.801203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>...</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>disease_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00000005_000.png</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2048</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.168</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00000005_001.png</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00000005_002.png</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00000005_003.png</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image Index Finding Labels  Follow-up #  Patient ID  Patient Age  \\\n",
       "3   00000002_000.png                           0           2           81   \n",
       "13  00000005_000.png                           0           5           69   \n",
       "14  00000005_001.png                           1           5           69   \n",
       "15  00000005_002.png                           2           5           69   \n",
       "16  00000005_003.png                           3           5           69   \n",
       "\n",
       "   Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "3               M            PA                 2500     2048   \n",
       "13              F            PA                 2048     2500   \n",
       "14              F            AP                 2500     2048   \n",
       "15              F            AP                 2500     2048   \n",
       "16              F            PA                 2992     2991   \n",
       "\n",
       "    OriginalImagePixelSpacing[x               ...                Nodule  Mass  \\\n",
       "3                         0.171               ...                     0     0   \n",
       "13                        0.168               ...                     0     0   \n",
       "14                        0.168               ...                     0     0   \n",
       "15                        0.168               ...                     0     0   \n",
       "16                        0.143               ...                     0     0   \n",
       "\n",
       "    Effusion  Pleural_Thickening  Infiltration  Atelectasis  Cardiomegaly  \\\n",
       "3          0                   0             0            0             0   \n",
       "13         0                   0             0            0             0   \n",
       "14         0                   0             0            0             0   \n",
       "15         0                   0             0            0             0   \n",
       "16         0                   0             0            0             0   \n",
       "\n",
       "    Consolidation  Emphysema                     disease_vec  \n",
       "3               0          0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "13              0          0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "14              0          0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "15              0          0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "16              0          0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(df['Finding Labels'][~df['Finding Labels'].str.contains('\\|')].unique())\n",
    "labels.remove('')\n",
    "\n",
    "for label in labels:\n",
    "    df[label] = df['Finding Labels'].map(lambda x: 1 if label in x else 0)\n",
    "df['disease_vec'] = df[labels].apply(lambda x: np.array(list(x)),axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T18:47:05.739770Z",
     "start_time": "2019-01-26T18:47:05.307638Z"
    }
   },
   "outputs": [],
   "source": [
    "# min_count = np.min(df_uni['Finding Labels'].value_counts())\n",
    "# df_rd = df_uni.groupby('Finding Labels',group_keys=False).apply(lambda df: df.sample(min_count))\n",
    "\n",
    "dataset = ChestDataset(data_dir,df)\n",
    "\n",
    "df['path'] = dataset.image_path\n",
    "\n",
    "train_list = [el[len(data_dir):] for i,el in enumerate(dataset.image_path) if not i%5 == 0]\n",
    "test_list = [el[len(data_dir):] for i,el in enumerate(dataset.image_path) if i%5 == 0]\n",
    "\n",
    "y_train = df['Finding Labels'][df['Image Index'].isin(test_list)]\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "\n",
    "# train_dt,test_dt = dataset.train_test(train_list,test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T18:47:18.043058Z",
     "start_time": "2019-01-26T18:47:18.039388Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('output/dense_train_list.txt', 'w') as f:\n",
    "#     for item in train_list:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n",
    "# with open('output/dense_test_list.txt', 'w') as f:\n",
    "#     for item in test_list:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n",
    "# train_files = train_dt.image_path\n",
    "# test_files = test_dt.image_path\n",
    "# train_folder = train_dt.dir\n",
    "# test_folder = test_dt.dir\n",
    "\n",
    "# print('Train # No Finding:',train_dt.labels.count('')/len(train_dt.labels))\n",
    "# print('Test # No Finding:',test_dt.labels.count('')/len(test_dt.labels))\n",
    "# labels = set(dataset.labels)\n",
    "# print('Statistics about the Dataset:\\n')\n",
    "# print('There are %d total chest deseases.' % len(labels))\n",
    "# print('There are %s total chest images.\\n' % len(dataset))\n",
    "# print('There are %d training chest images.' % len(train_dt))\n",
    "# print('There are %d test chest images.'% len(test_dt))\n",
    "# for lab in labels:\n",
    "#     print('# of %s: %.3f%%'%(lab,100*dataset.labels.count(lab)/len(dataset.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T18:51:10.640101Z",
     "start_time": "2019-01-26T18:50:05.392765Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 8, 8, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                917518    \n",
      "=================================================================\n",
      "Total params: 7,955,022\n",
      "Trainable params: 7,871,374\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ADD YOUR MODEL\n",
    "im_width,im_heigth = 256,256\n",
    "densenet = DenseNet121(weights='imagenet', include_top=False,input_shape = (im_width,im_heigth,3))\n",
    "\n",
    "# # Freeze some layers\n",
    "# for layer in densenet.layers[:100]:\n",
    "#     layer.trainable = False\n",
    "    \n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(densenet)\n",
    "\n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(72))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.248))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T18:51:29.092456Z",
     "start_time": "2019-01-26T18:51:29.079179Z"
    }
   },
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T19:00:31.954200Z",
     "start_time": "2019-01-26T19:00:21.250810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 1 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 1 images\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   samplewise_center=True, \n",
    "                                   samplewise_std_normalization=True,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip = False, \n",
    "                                   height_shift_range= 0.05, \n",
    "                                   width_shift_range=0.1, \n",
    "                                   rotation_range=5,\n",
    "                                   shear_range = 0.1,\n",
    "                                   fill_mode = 'reflect',\n",
    "                                   zoom_range=0.15)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "df_train = df[df['Image Index'].isin(train_list)]\n",
    "df_test = df[df['Image Index'].isin(test_list)]\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 20\n",
    "val_batchsize = 20\n",
    "\n",
    "train_generator = flow_from_dataframe(train_datagen, df_train, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = (im_width,im_heigth),\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = train_batchsize)\n",
    "\n",
    "validation_generator = flow_from_dataframe(validation_datagen, df_test, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = (im_width,im_heigth),\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = val_batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-26T18:56:00.940118Z",
     "start_time": "2019-01-26T18:51:51.751262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-43:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 666, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 661, in <lambda>\n",
      "    initargs=(seqs, self.random_seed))\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "Exception in thread Thread-42:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 666, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 661, in <lambda>\n",
      "    initargs=(seqs, self.random_seed))\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-23-be535150543b>\", line 20, in <module>\n",
      "    use_multiprocessing=True)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/keras/engine/training.py\", line 1418, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/keras/engine/training_generator.py\", line 181, in fit_generator\n",
      "    generator_output = next(output_generator)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 685, in get\n",
      "    inputs = self.queue.get(block=True).get()\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/queue.py\", line 164, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/threading.py\", line 295, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/yair/anaconda3/envs/final/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='output/logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "filepath = \"output/checkpoint_{}.hdf5\".format(model_name)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=20,\n",
    "    class_weight=class_weights,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard,checkpoint],\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"output/{}.json\".format(model_name), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"output/{}.h5\".format(model_name))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "fig.savefig('output/history_{}.png'.format(model_name))\n",
    "\n",
    "\n",
    "prediction = model.predict_generator(validation_generator,\n",
    "                                     steps=len(validation_generator),\n",
    "                                     pickle_safe=True,\n",
    "                                     verbose=1)\n",
    "\n",
    "\n",
    "preds = np.argmax(prediction,axis=1)\n",
    "\n",
    "y_true = np.zeros((preds.shape[0],validation_generator.num_classes))\n",
    "y_true[np.arange(preds.shape[0]), validation_generator.classes] = 1\n",
    "inv_map = {v:k for k,v in validation_generator.class_indices.items()}\n",
    "pred_cat = [inv_map[i] for i in preds]\n",
    "\n",
    "report = classification_report(validation_generator.classes,preds)\n",
    "np.save('output/report_{}.npy'.format(model_name),report)\n",
    "print(report)\n",
    "print('Accuracy score: ',accuracy_score(validation_generator.classes,preds))\n",
    "\n",
    "score = model.evaluate_generator(validation_generator,\n",
    "                                 steps=len(validation_generator),\n",
    "                                 pickle_safe=True)\n",
    "print('Accuracy Keras: ', score[1])\n",
    "\n",
    "# Auc scores\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(validation_generator.num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], prediction[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "for i in range(validation_generator.num_classes):\n",
    "    plt.plot(fpr[i], tpr[i],\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(inv_map[i], roc_auc[i]))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "fig.savefig('output/roc_curve_{}.png'.format(model_name))\n",
    "\n",
    "print('End Of Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
