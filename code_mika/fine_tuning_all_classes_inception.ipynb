{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.datasets import load_files\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16, DenseNet121, InceptionV3\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chown -R ds:ds /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions: \n",
      "\n",
      "Atelectasis train: 15.9895\n",
      "Atelectasis test: 10.6340\n",
      "*********************\n",
      "Cardiomegaly train: 4.0766\n",
      "Cardiomegaly test: 7.8382\n",
      "*********************\n",
      "Consolidation train: 4.0077\n",
      "Consolidation test: 5.1922\n",
      "*********************\n",
      "Edema train: 1.2533\n",
      "Edema test: 2.3465\n",
      "*********************\n",
      "Effusion train: 12.5603\n",
      "Effusion test: 11.6326\n",
      "*********************\n",
      "Emphysema train: 3.4155\n",
      "Emphysema test: 3.2451\n",
      "*********************\n",
      "Fibrosis train: 4.0628\n",
      "Fibrosis test: 3.7943\n",
      "*********************\n",
      "Hernia train: 0.4132\n",
      "Hernia test: 1.1483\n",
      "*********************\n",
      "Infiltration train: 24.4732\n",
      "Infiltration test: 29.8552\n",
      "*********************\n",
      "Mass train: 6.9274\n",
      "Mass test: 3.4448\n",
      "*********************\n",
      "Nodule train: 10.8525\n",
      "Nodule test: 4.5432\n",
      "*********************\n",
      "Pleural_Thickening train: 4.3796\n",
      "Pleural_Thickening test: 4.9426\n",
      "*********************\n",
      "Pneumonia train: 0.9778\n",
      "Pneumonia test: 1.1982\n",
      "*********************\n",
      "Pneumothorax train: 6.6107\n",
      "Pneumothorax test: 10.1847\n",
      "*********************\n",
      "\n",
      "Statistics about the Dataset:\n",
      "\n",
      "There are 14 total chest deseases.\n",
      "There are 9264 total chest images.\n",
      "\n",
      "There are 7261 training chest images.\n",
      "There are 2003 test chest images.\n"
     ]
    }
   ],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path, n_classes):\n",
    "    \"\"\"Returns the path and the Label from the folder\"\"\"\n",
    "    data = load_files(path)\n",
    "    chest_files = np.array(data['filenames'])\n",
    "    chest_targets = np_utils.to_categorical(np.array(data['target']), n_classes)\n",
    "    return chest_files, chest_targets\n",
    "\n",
    "# load list of dog names\n",
    "labels = [item[18:-1] for item in sorted(glob(\"../imgs/all/train/*/\"))]\n",
    "n_classes = len(labels)\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('../imgs/all/train', n_classes)\n",
    "test_files, test_targets = load_dataset('../imgs/all/test', n_classes)\n",
    "\n",
    "# Img size\n",
    "img_width, img_height, channels = 224, 224, 3\n",
    "\n",
    "#proportions\n",
    "train_prop = np.count_nonzero(train_targets, axis=0) / len(train_targets)\n",
    "test_prop = np.count_nonzero(test_targets, axis=0) / len(test_targets)\n",
    "\n",
    "print('Proportions: \\n')\n",
    "for index, label in enumerate(labels):\n",
    "    print('{} train: {:.4f}'.format(label, train_prop[index]*100))\n",
    "    print('{} test: {:.4f}'.format(label, test_prop[index]*100))\n",
    "    print('*********************')\n",
    "\n",
    "print('\\nStatistics about the Dataset:\\n')\n",
    "print('There are %d total chest deseases.' % len(labels))\n",
    "print('There are %s total chest images.\\n' % len(np.hstack([train_files, test_files])))\n",
    "print('There are %d training chest images.' % len(train_files))\n",
    "print('There are %d test chest images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 111, 111, 32) 864         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_471 (BatchN (None, 111, 111, 32) 96          conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_471 (Activation)     (None, 111, 111, 32) 0           batch_normalization_471[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 109, 109, 32) 9216        activation_471[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_472 (BatchN (None, 109, 109, 32) 96          conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_472 (Activation)     (None, 109, 109, 32) 0           batch_normalization_472[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)             (None, 109, 109, 64) 18432       activation_472[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_473 (BatchN (None, 109, 109, 64) 192         conv2d_473[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_473 (Activation)     (None, 109, 109, 64) 0           batch_normalization_473[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 54, 54, 64)   0           activation_473[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_474 (BatchN (None, 54, 54, 80)   240         conv2d_474[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_474 (Activation)     (None, 54, 54, 80)   0           batch_normalization_474[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)             (None, 52, 52, 192)  138240      activation_474[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_475 (BatchN (None, 52, 52, 192)  576         conv2d_475[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_475 (Activation)     (None, 52, 52, 192)  0           batch_normalization_475[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 25, 25, 192)  0           activation_475[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_479 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_479 (BatchN (None, 25, 25, 64)   192         conv2d_479[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_479 (Activation)     (None, 25, 25, 64)   0           batch_normalization_479[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_477 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_480 (Conv2D)             (None, 25, 25, 96)   55296       activation_479[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_477 (BatchN (None, 25, 25, 48)   144         conv2d_477[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_480 (BatchN (None, 25, 25, 96)   288         conv2d_480[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_477 (Activation)     (None, 25, 25, 48)   0           batch_normalization_477[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_480 (Activation)     (None, 25, 25, 96)   0           batch_normalization_480[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_46 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_478 (Conv2D)             (None, 25, 25, 64)   76800       activation_477[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_481 (Conv2D)             (None, 25, 25, 96)   82944       activation_480[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_482 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_46[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_476 (BatchN (None, 25, 25, 64)   192         conv2d_476[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_478 (BatchN (None, 25, 25, 64)   192         conv2d_478[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_481 (BatchN (None, 25, 25, 96)   288         conv2d_481[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_482 (BatchN (None, 25, 25, 32)   96          conv2d_482[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_476 (Activation)     (None, 25, 25, 64)   0           batch_normalization_476[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_478 (Activation)     (None, 25, 25, 64)   0           batch_normalization_478[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_481 (Activation)     (None, 25, 25, 96)   0           batch_normalization_481[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_482 (Activation)     (None, 25, 25, 32)   0           batch_normalization_482[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_476[0][0]             \n",
      "                                                                 activation_478[0][0]             \n",
      "                                                                 activation_481[0][0]             \n",
      "                                                                 activation_482[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_486 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_486 (BatchN (None, 25, 25, 64)   192         conv2d_486[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_486 (Activation)     (None, 25, 25, 64)   0           batch_normalization_486[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_487 (Conv2D)             (None, 25, 25, 96)   55296       activation_486[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_484 (BatchN (None, 25, 25, 48)   144         conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_487 (BatchN (None, 25, 25, 96)   288         conv2d_487[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_484 (Activation)     (None, 25, 25, 48)   0           batch_normalization_484[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_487 (Activation)     (None, 25, 25, 96)   0           batch_normalization_487[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_47 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)             (None, 25, 25, 64)   76800       activation_484[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)             (None, 25, 25, 96)   82944       activation_487[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_47[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_483 (BatchN (None, 25, 25, 64)   192         conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_485 (BatchN (None, 25, 25, 64)   192         conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_488 (BatchN (None, 25, 25, 96)   288         conv2d_488[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_489 (BatchN (None, 25, 25, 64)   192         conv2d_489[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_483 (Activation)     (None, 25, 25, 64)   0           batch_normalization_483[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_485 (Activation)     (None, 25, 25, 64)   0           batch_normalization_485[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_488 (Activation)     (None, 25, 25, 96)   0           batch_normalization_488[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_489 (Activation)     (None, 25, 25, 64)   0           batch_normalization_489[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_483[0][0]             \n",
      "                                                                 activation_485[0][0]             \n",
      "                                                                 activation_488[0][0]             \n",
      "                                                                 activation_489[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_493 (BatchN (None, 25, 25, 64)   192         conv2d_493[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_493 (Activation)     (None, 25, 25, 64)   0           batch_normalization_493[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)             (None, 25, 25, 96)   55296       activation_493[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_491 (BatchN (None, 25, 25, 48)   144         conv2d_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_494 (BatchN (None, 25, 25, 96)   288         conv2d_494[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_491 (Activation)     (None, 25, 25, 48)   0           batch_normalization_491[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_494 (Activation)     (None, 25, 25, 96)   0           batch_normalization_494[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_48 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)             (None, 25, 25, 64)   76800       activation_491[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)             (None, 25, 25, 96)   82944       activation_494[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_48[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_490 (BatchN (None, 25, 25, 64)   192         conv2d_490[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_492 (BatchN (None, 25, 25, 64)   192         conv2d_492[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_495 (BatchN (None, 25, 25, 96)   288         conv2d_495[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_496 (BatchN (None, 25, 25, 64)   192         conv2d_496[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_490 (Activation)     (None, 25, 25, 64)   0           batch_normalization_490[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_492 (Activation)     (None, 25, 25, 64)   0           batch_normalization_492[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_495 (Activation)     (None, 25, 25, 96)   0           batch_normalization_495[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_496 (Activation)     (None, 25, 25, 64)   0           batch_normalization_496[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_490[0][0]             \n",
      "                                                                 activation_492[0][0]             \n",
      "                                                                 activation_495[0][0]             \n",
      "                                                                 activation_496[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_498 (BatchN (None, 25, 25, 64)   192         conv2d_498[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_498 (Activation)     (None, 25, 25, 64)   0           batch_normalization_498[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)             (None, 25, 25, 96)   55296       activation_498[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_499 (BatchN (None, 25, 25, 96)   288         conv2d_499[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_499 (Activation)     (None, 25, 25, 96)   0           batch_normalization_499[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)             (None, 12, 12, 96)   82944       activation_499[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_497 (BatchN (None, 12, 12, 384)  1152        conv2d_497[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_500 (BatchN (None, 12, 12, 96)   288         conv2d_500[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_497 (Activation)     (None, 12, 12, 384)  0           batch_normalization_497[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_500 (Activation)     (None, 12, 12, 96)   0           batch_normalization_500[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_497[0][0]             \n",
      "                                                                 activation_500[0][0]             \n",
      "                                                                 max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_505 (BatchN (None, 12, 12, 128)  384         conv2d_505[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_505 (Activation)     (None, 12, 12, 128)  0           batch_normalization_505[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)             (None, 12, 12, 128)  114688      activation_505[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_506 (BatchN (None, 12, 12, 128)  384         conv2d_506[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_506 (Activation)     (None, 12, 12, 128)  0           batch_normalization_506[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)             (None, 12, 12, 128)  114688      activation_506[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_502 (BatchN (None, 12, 12, 128)  384         conv2d_502[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_507 (BatchN (None, 12, 12, 128)  384         conv2d_507[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_502 (Activation)     (None, 12, 12, 128)  0           batch_normalization_502[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_507 (Activation)     (None, 12, 12, 128)  0           batch_normalization_507[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)             (None, 12, 12, 128)  114688      activation_502[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)             (None, 12, 12, 128)  114688      activation_507[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_503 (BatchN (None, 12, 12, 128)  384         conv2d_503[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_508 (BatchN (None, 12, 12, 128)  384         conv2d_508[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_503 (Activation)     (None, 12, 12, 128)  0           batch_normalization_503[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_508 (Activation)     (None, 12, 12, 128)  0           batch_normalization_508[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_49 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)             (None, 12, 12, 192)  172032      activation_503[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_509 (Conv2D)             (None, 12, 12, 192)  172032      activation_508[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_49[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_501 (BatchN (None, 12, 12, 192)  576         conv2d_501[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_504 (BatchN (None, 12, 12, 192)  576         conv2d_504[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_509 (BatchN (None, 12, 12, 192)  576         conv2d_509[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_510 (BatchN (None, 12, 12, 192)  576         conv2d_510[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_501 (Activation)     (None, 12, 12, 192)  0           batch_normalization_501[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_504 (Activation)     (None, 12, 12, 192)  0           batch_normalization_504[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_509 (Activation)     (None, 12, 12, 192)  0           batch_normalization_509[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_510 (Activation)     (None, 12, 12, 192)  0           batch_normalization_510[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_501[0][0]             \n",
      "                                                                 activation_504[0][0]             \n",
      "                                                                 activation_509[0][0]             \n",
      "                                                                 activation_510[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_515 (BatchN (None, 12, 12, 160)  480         conv2d_515[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_515 (Activation)     (None, 12, 12, 160)  0           batch_normalization_515[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_516 (Conv2D)             (None, 12, 12, 160)  179200      activation_515[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_516 (BatchN (None, 12, 12, 160)  480         conv2d_516[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_516 (Activation)     (None, 12, 12, 160)  0           batch_normalization_516[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_517 (Conv2D)             (None, 12, 12, 160)  179200      activation_516[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_512 (BatchN (None, 12, 12, 160)  480         conv2d_512[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_517 (BatchN (None, 12, 12, 160)  480         conv2d_517[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_512 (Activation)     (None, 12, 12, 160)  0           batch_normalization_512[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_517 (Activation)     (None, 12, 12, 160)  0           batch_normalization_517[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)             (None, 12, 12, 160)  179200      activation_512[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)             (None, 12, 12, 160)  179200      activation_517[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_513 (BatchN (None, 12, 12, 160)  480         conv2d_513[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_518 (BatchN (None, 12, 12, 160)  480         conv2d_518[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_513 (Activation)     (None, 12, 12, 160)  0           batch_normalization_513[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_518 (Activation)     (None, 12, 12, 160)  0           batch_normalization_518[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_50 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)             (None, 12, 12, 192)  215040      activation_513[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)             (None, 12, 12, 192)  215040      activation_518[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_50[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_511 (BatchN (None, 12, 12, 192)  576         conv2d_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_514 (BatchN (None, 12, 12, 192)  576         conv2d_514[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_519 (BatchN (None, 12, 12, 192)  576         conv2d_519[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_520 (BatchN (None, 12, 12, 192)  576         conv2d_520[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_511 (Activation)     (None, 12, 12, 192)  0           batch_normalization_511[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_514 (Activation)     (None, 12, 12, 192)  0           batch_normalization_514[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_519 (Activation)     (None, 12, 12, 192)  0           batch_normalization_519[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_520 (Activation)     (None, 12, 12, 192)  0           batch_normalization_520[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_511[0][0]             \n",
      "                                                                 activation_514[0][0]             \n",
      "                                                                 activation_519[0][0]             \n",
      "                                                                 activation_520[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_525 (BatchN (None, 12, 12, 160)  480         conv2d_525[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_525 (Activation)     (None, 12, 12, 160)  0           batch_normalization_525[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)             (None, 12, 12, 160)  179200      activation_525[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_526 (BatchN (None, 12, 12, 160)  480         conv2d_526[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_526 (Activation)     (None, 12, 12, 160)  0           batch_normalization_526[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)             (None, 12, 12, 160)  179200      activation_526[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_522 (BatchN (None, 12, 12, 160)  480         conv2d_522[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_527 (BatchN (None, 12, 12, 160)  480         conv2d_527[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_522 (Activation)     (None, 12, 12, 160)  0           batch_normalization_522[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_527 (Activation)     (None, 12, 12, 160)  0           batch_normalization_527[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)             (None, 12, 12, 160)  179200      activation_522[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)             (None, 12, 12, 160)  179200      activation_527[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_523 (BatchN (None, 12, 12, 160)  480         conv2d_523[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_528 (BatchN (None, 12, 12, 160)  480         conv2d_528[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_523 (Activation)     (None, 12, 12, 160)  0           batch_normalization_523[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_528 (Activation)     (None, 12, 12, 160)  0           batch_normalization_528[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_51 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)             (None, 12, 12, 192)  215040      activation_523[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)             (None, 12, 12, 192)  215040      activation_528[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_51[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_521 (BatchN (None, 12, 12, 192)  576         conv2d_521[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_524 (BatchN (None, 12, 12, 192)  576         conv2d_524[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_529 (BatchN (None, 12, 12, 192)  576         conv2d_529[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_530 (BatchN (None, 12, 12, 192)  576         conv2d_530[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_521 (Activation)     (None, 12, 12, 192)  0           batch_normalization_521[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_524 (Activation)     (None, 12, 12, 192)  0           batch_normalization_524[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_529 (Activation)     (None, 12, 12, 192)  0           batch_normalization_529[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_530 (Activation)     (None, 12, 12, 192)  0           batch_normalization_530[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_521[0][0]             \n",
      "                                                                 activation_524[0][0]             \n",
      "                                                                 activation_529[0][0]             \n",
      "                                                                 activation_530[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_535 (BatchN (None, 12, 12, 192)  576         conv2d_535[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_535 (Activation)     (None, 12, 12, 192)  0           batch_normalization_535[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_536 (Conv2D)             (None, 12, 12, 192)  258048      activation_535[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_536 (BatchN (None, 12, 12, 192)  576         conv2d_536[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_536 (Activation)     (None, 12, 12, 192)  0           batch_normalization_536[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_537 (Conv2D)             (None, 12, 12, 192)  258048      activation_536[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_532 (BatchN (None, 12, 12, 192)  576         conv2d_532[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_537 (BatchN (None, 12, 12, 192)  576         conv2d_537[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_532 (Activation)     (None, 12, 12, 192)  0           batch_normalization_532[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_537 (Activation)     (None, 12, 12, 192)  0           batch_normalization_537[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)             (None, 12, 12, 192)  258048      activation_532[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_538 (Conv2D)             (None, 12, 12, 192)  258048      activation_537[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_533 (BatchN (None, 12, 12, 192)  576         conv2d_533[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_538 (BatchN (None, 12, 12, 192)  576         conv2d_538[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_533 (Activation)     (None, 12, 12, 192)  0           batch_normalization_533[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_538 (Activation)     (None, 12, 12, 192)  0           batch_normalization_538[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_52 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)             (None, 12, 12, 192)  258048      activation_533[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)             (None, 12, 12, 192)  258048      activation_538[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_52[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_531 (BatchN (None, 12, 12, 192)  576         conv2d_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_534 (BatchN (None, 12, 12, 192)  576         conv2d_534[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_539 (BatchN (None, 12, 12, 192)  576         conv2d_539[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_540 (BatchN (None, 12, 12, 192)  576         conv2d_540[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_531 (Activation)     (None, 12, 12, 192)  0           batch_normalization_531[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_534 (Activation)     (None, 12, 12, 192)  0           batch_normalization_534[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_539 (Activation)     (None, 12, 12, 192)  0           batch_normalization_539[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_540 (Activation)     (None, 12, 12, 192)  0           batch_normalization_540[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_531[0][0]             \n",
      "                                                                 activation_534[0][0]             \n",
      "                                                                 activation_539[0][0]             \n",
      "                                                                 activation_540[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_543 (BatchN (None, 12, 12, 192)  576         conv2d_543[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_543 (Activation)     (None, 12, 12, 192)  0           batch_normalization_543[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)             (None, 12, 12, 192)  258048      activation_543[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_544 (BatchN (None, 12, 12, 192)  576         conv2d_544[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_544 (Activation)     (None, 12, 12, 192)  0           batch_normalization_544[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_545 (Conv2D)             (None, 12, 12, 192)  258048      activation_544[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_541 (BatchN (None, 12, 12, 192)  576         conv2d_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_545 (BatchN (None, 12, 12, 192)  576         conv2d_545[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_541 (Activation)     (None, 12, 12, 192)  0           batch_normalization_541[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_545 (Activation)     (None, 12, 12, 192)  0           batch_normalization_545[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)             (None, 5, 5, 320)    552960      activation_541[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)             (None, 5, 5, 192)    331776      activation_545[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_542 (BatchN (None, 5, 5, 320)    960         conv2d_542[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_546 (BatchN (None, 5, 5, 192)    576         conv2d_546[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_542 (Activation)     (None, 5, 5, 320)    0           batch_normalization_542[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_546 (Activation)     (None, 5, 5, 192)    0           batch_normalization_546[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_542[0][0]             \n",
      "                                                                 activation_546[0][0]             \n",
      "                                                                 max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_551 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_551 (BatchN (None, 5, 5, 448)    1344        conv2d_551[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_551 (Activation)     (None, 5, 5, 448)    0           batch_normalization_551[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_552 (Conv2D)             (None, 5, 5, 384)    1548288     activation_551[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_548 (BatchN (None, 5, 5, 384)    1152        conv2d_548[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_552 (BatchN (None, 5, 5, 384)    1152        conv2d_552[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_548 (Activation)     (None, 5, 5, 384)    0           batch_normalization_548[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_552 (Activation)     (None, 5, 5, 384)    0           batch_normalization_552[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_549 (Conv2D)             (None, 5, 5, 384)    442368      activation_548[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_550 (Conv2D)             (None, 5, 5, 384)    442368      activation_548[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_553 (Conv2D)             (None, 5, 5, 384)    442368      activation_552[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_554 (Conv2D)             (None, 5, 5, 384)    442368      activation_552[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_53 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_549 (BatchN (None, 5, 5, 384)    1152        conv2d_549[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_550 (BatchN (None, 5, 5, 384)    1152        conv2d_550[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_553 (BatchN (None, 5, 5, 384)    1152        conv2d_553[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_554 (BatchN (None, 5, 5, 384)    1152        conv2d_554[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_555 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_53[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_547 (BatchN (None, 5, 5, 320)    960         conv2d_547[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_549 (Activation)     (None, 5, 5, 384)    0           batch_normalization_549[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_550 (Activation)     (None, 5, 5, 384)    0           batch_normalization_550[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_553 (Activation)     (None, 5, 5, 384)    0           batch_normalization_553[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_554 (Activation)     (None, 5, 5, 384)    0           batch_normalization_554[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_555 (BatchN (None, 5, 5, 192)    576         conv2d_555[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_547 (Activation)     (None, 5, 5, 320)    0           batch_normalization_547[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_549[0][0]             \n",
      "                                                                 activation_550[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 5, 5, 768)    0           activation_553[0][0]             \n",
      "                                                                 activation_554[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_555 (Activation)     (None, 5, 5, 192)    0           batch_normalization_555[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_547[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 activation_555[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_560 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_560 (BatchN (None, 5, 5, 448)    1344        conv2d_560[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_560 (Activation)     (None, 5, 5, 448)    0           batch_normalization_560[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_557 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_561 (Conv2D)             (None, 5, 5, 384)    1548288     activation_560[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_557 (BatchN (None, 5, 5, 384)    1152        conv2d_557[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_561 (BatchN (None, 5, 5, 384)    1152        conv2d_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_557 (Activation)     (None, 5, 5, 384)    0           batch_normalization_557[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_561 (Activation)     (None, 5, 5, 384)    0           batch_normalization_561[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_558 (Conv2D)             (None, 5, 5, 384)    442368      activation_557[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_559 (Conv2D)             (None, 5, 5, 384)    442368      activation_557[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_562 (Conv2D)             (None, 5, 5, 384)    442368      activation_561[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_563 (Conv2D)             (None, 5, 5, 384)    442368      activation_561[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_54 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_556 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_558 (BatchN (None, 5, 5, 384)    1152        conv2d_558[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_559 (BatchN (None, 5, 5, 384)    1152        conv2d_559[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_562 (BatchN (None, 5, 5, 384)    1152        conv2d_562[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_563 (BatchN (None, 5, 5, 384)    1152        conv2d_563[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_54[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_556 (BatchN (None, 5, 5, 320)    960         conv2d_556[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_558 (Activation)     (None, 5, 5, 384)    0           batch_normalization_558[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_559 (Activation)     (None, 5, 5, 384)    0           batch_normalization_559[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_562 (Activation)     (None, 5, 5, 384)    0           batch_normalization_562[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_563 (Activation)     (None, 5, 5, 384)    0           batch_normalization_563[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_564 (BatchN (None, 5, 5, 192)    576         conv2d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_556 (Activation)     (None, 5, 5, 320)    0           batch_normalization_556[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_558[0][0]             \n",
      "                                                                 activation_559[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 5, 5, 768)    0           activation_562[0][0]             \n",
      "                                                                 activation_563[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_564 (Activation)     (None, 5, 5, 192)    0           batch_normalization_564[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_556[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 activation_564[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 14)           528142      mixed10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,330,926\n",
      "Trainable params: 22,296,494\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_cnn = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, channels))\n",
    "model_top = Sequential()\n",
    "model_top.add(GlobalAveragePooling2D(input_shape = model_cnn.output_shape[1:], data_format=None))\n",
    "model_top.add(Dense(256, activation='relu'))\n",
    "model_top.add(Dropout(0.5))\n",
    "model_top.add(Dense(14, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs=model_cnn.input, outputs=model_top(model_cnn.output))\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6e6eebbb7678>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnb_train_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnb_validation_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Layers: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "train_data_dir = '../imgs/all/train'\n",
    "validation_data_dir = '../imgs/all/test'\n",
    "batch_size = 16\n",
    "epochs = 15\n",
    "nb_train_samples = len(train_files) // batch_size\n",
    "nb_validation_samples = len(test_files) // batch_size\n",
    "print('Layers: {}'.format(len(model.layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7261 images belonging to 14 classes.\n",
      "Found 2003 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\micka\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=15, validation_data=<keras_pre..., callbacks=[<keras.ca..., steps_per_epoch=28, validation_steps=125)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "28/28 [==============================] - 1231s 44s/step - loss: 2.5052 - acc: 0.1540 - val_loss: 2.4592 - val_acc: 0.2375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.45919, saving model to weights.best.INCEPTION.all.hdf5\n",
      "Epoch 2/15\n",
      "28/28 [==============================] - 1135s 41s/step - loss: 2.3929 - acc: 0.1897 - val_loss: 2.5242 - val_acc: 0.2979\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.45919\n",
      "Epoch 3/15\n",
      "28/28 [==============================] - 1126s 40s/step - loss: 2.3464 - acc: 0.1987 - val_loss: 2.6934 - val_acc: 0.2934\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.45919\n",
      "Epoch 4/15\n",
      "28/28 [==============================] - 1139s 41s/step - loss: 2.3483 - acc: 0.2232 - val_loss: 2.7384 - val_acc: 0.3025\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.45919\n",
      "Epoch 5/15\n",
      "28/28 [==============================] - 1130s 40s/step - loss: 2.2631 - acc: 0.2656 - val_loss: 2.9672 - val_acc: 0.2954\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.45919\n",
      "Epoch 6/15\n",
      "28/28 [==============================] - 1127s 40s/step - loss: 2.2987 - acc: 0.2500 - val_loss: 3.0127 - val_acc: 0.2999\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.45919\n",
      "Epoch 7/15\n",
      "28/28 [==============================] - 1143s 41s/step - loss: 2.2665 - acc: 0.2321 - val_loss: 3.3730 - val_acc: 0.2994\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.45919\n",
      "Epoch 8/15\n",
      "28/28 [==============================] - 1128s 40s/step - loss: 2.2976 - acc: 0.2388 - val_loss: 3.4743 - val_acc: 0.2939\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.45919\n",
      "Epoch 9/15\n",
      "28/28 [==============================] - 1125s 40s/step - loss: 2.3934 - acc: 0.2121 - val_loss: 2.8139 - val_acc: 0.3005\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.45919\n",
      "Epoch 10/15\n",
      "28/28 [==============================] - 1142s 41s/step - loss: 2.3824 - acc: 0.2545 - val_loss: 2.7940 - val_acc: 0.2964\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.45919\n",
      "Epoch 11/15\n",
      "28/28 [==============================] - 1134s 41s/step - loss: 2.2109 - acc: 0.2478 - val_loss: 3.0742 - val_acc: 0.2949\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.45919\n",
      "Epoch 12/15\n",
      "28/28 [==============================] - 1123s 40s/step - loss: 2.2035 - acc: 0.2991 - val_loss: 3.0965 - val_acc: 0.3040\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.45919\n",
      "Epoch 13/15\n",
      "28/28 [==============================] - 1130s 40s/step - loss: 2.2315 - acc: 0.2656 - val_loss: 3.2992 - val_acc: 0.2954\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.45919\n",
      "Epoch 14/15\n",
      "28/28 [==============================] - 1125s 40s/step - loss: 2.2103 - acc: 0.2746 - val_loss: 3.0803 - val_acc: 0.2974\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.45919\n",
      "Epoch 15/15\n",
      "28/28 [==============================] - 1122s 40s/step - loss: 2.2756 - acc: 0.2656 - val_loss: 3.5688 - val_acc: 0.2989\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.45919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df016c6be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeze Layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Change the learning rate \"\"\"\n",
    "    lrate = 0.001\n",
    "    if epoch > 10:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 50:\n",
    "        lrate = 0.0003\n",
    "    return lrate\n",
    "    \n",
    "# Fit the model    \n",
    "# checkpointer = ModelCheckpoint(filepath='weights.best.INCEPTION.all.hdf5', verbose=1, save_best_only=True)\n",
    "History = model.fit_generator(train_generator, samples_per_epoch=nb_train_samples, epochs=epochs,\n",
    "                    validation_data=validation_generator, nb_val_samples=nb_validation_samples,\n",
    "                   callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'History' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-3f0c622c9645>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m211\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'History' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(10,10))  \n",
    "\n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(History.history['acc'])  \n",
    "plt.plot(History.history['val_acc'])  \n",
    "plt.title('Model Accuracy')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "plt.plot(History.history['loss'])  \n",
    "plt.plot(History.history['val_loss'])  \n",
    "plt.title('Model Loss')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 8 0 ... 0 0 8]\n"
     ]
    }
   ],
   "source": [
    "# Predictions (1)\n",
    "# if you forget to reset the test_generator you will get outputs in a weird order.\n",
    "validation_generator.reset()\n",
    "predictions1 = model.predict_generator(validation_generator, steps=nb_validation_samples)\n",
    "\n",
    "#label with corresponding largest predictied probability\n",
    "predictions1 = np.argmax(predictions1, axis=1)\n",
    "\n",
    "print(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions (2)\n",
    "### Load the model weights with the best validation loss.\n",
    "model.load_weights('weights.best.INCEPTION.all.hdf5')\n",
    "\n",
    "predictions2 = [np.ma.argmax(model.predict(feature[0]),1) for feature in validation_generator]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(predictions2)==np.argmax(test_targets, axis=1))/len(predictions2)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 0, 8, 8, 8, 0, 8, 8, 0, 8, 0, 0, 0, 8, 8, 8], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ma.argmax(model.predict(validation_generator.next()[0]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 145s 9s/step\n",
      "2.436826854944229 0.20703125\n"
     ]
    }
   ],
   "source": [
    "# Predictions (3)\n",
    "\n",
    "(eval_loss, eval_accuracy) = model.evaluate_generator(validation_generator,steps = batch_size, verbose=1)\n",
    "\n",
    "print(eval_loss, eval_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  1,  4, ..., 10,  4,  4], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.argmax(test_targets, axis=1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2003, 2000)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true), len(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       Atelectasis       0.00      0.00      0.00       213\n",
      "      Cardiomegaly       0.00      0.00      0.00       157\n",
      "     Consolidation       0.00      0.00      0.00       104\n",
      "             Edema       0.00      0.00      0.00        47\n",
      "          Effusion       0.00      0.00      0.00       231\n",
      "         Emphysema       0.00      0.00      0.00        65\n",
      "          Fibrosis       0.00      0.00      0.00        76\n",
      "            Hernia       0.00      0.00      0.00        23\n",
      "      Infiltration       0.30      1.00      0.46       598\n",
      "              Mass       0.00      0.00      0.00        69\n",
      "            Nodule       0.00      0.00      0.00        90\n",
      "Pleural_Thickening       0.00      0.00      0.00        99\n",
      "         Pneumonia       0.00      0.00      0.00        24\n",
      "      Pneumothorax       0.00      0.00      0.00       204\n",
      "\n",
      "         micro avg       0.30      0.30      0.30      2000\n",
      "         macro avg       0.02      0.07      0.03      2000\n",
      "      weighted avg       0.09      0.30      0.14      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true[:2000], predictions, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
