{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.datasets import load_files\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16, DenseNet121, InceptionV3\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device_lib.list_local_devices())\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chown -R ds:ds /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_DIR = \"../data/Data_Entry_2017.csv\"\n",
    "IMG_DIR = \"/data/xray_chest_final\"\n",
    "TRAIN_LIST = \"../data/train_val_list.txt\"\n",
    "TEST_LIST = \"../data/test_list.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           58              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           81              M            PA                 2500     2048   \n",
       "4           81              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  \n",
       "0                        0.143  0.143  \n",
       "1                        0.143  0.143  \n",
       "2                        0.168  0.168  \n",
       "3                        0.171  0.171  \n",
       "4                        0.143  0.143  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_entry = pd.read_csv(DF_DIR)\n",
    "df = df_data_entry.iloc[:,:11]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows having no. of disease\n",
    "df['labels_count'] = df['Finding Labels'].apply(lambda text: len(text.split('|')) if(text != 'No Finding') else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open train/test lists\n",
    "with open(TRAIN_LIST, 'r') as train_items:\n",
    "    train_list = train_items.readlines()\n",
    "train_list = [item.strip() for item in train_list]\n",
    "\n",
    "with open(TEST_LIST, 'r') as test_items:\n",
    "    test_list = test_items.readlines()\n",
    "test_list = [item.strip() for item in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(train_test):\n",
    "    dest = IMG_DIR\n",
    "    if not os.path.exists(os.path.join(dest, train_test)):\n",
    "        os.mkdir(os.path.join(dest, train_test))\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def split_items(train_val_test_list, category):\n",
    "    try:\n",
    "        dest = os.path.join(IMG_DIR, category)\n",
    "        for item in train_val_test_list:\n",
    "            _from = os.path.join(IMG_DIR, item)\n",
    "            \n",
    "            folder = df.loc[df['Image Index'] == item, 'Finding Labels'].values[0]  # Disease\n",
    "            count_labels = df.loc[df['Image Index'] == item,'labels_count'].values[0]\n",
    "            \n",
    "            if count_labels == 1: # keep only 1 disease:\n",
    "                if not os.path.exists(os.path.join(dest, folder)):\n",
    "                    os.mkdir(os.path.join(dest, folder))\n",
    "                    shutil.copy(_from, os.path.join(dest, folder))\n",
    "                else:\n",
    "                    shutil.copy(_from, os.path.join(dest, folder))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through function\n",
    "train_test_split('train')\n",
    "train_test_split('test')\n",
    "\n",
    "split_items(train_list, 'train')\n",
    "split_items(test_list, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glob(dest+'/train/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path, n_classes):\n",
    "    \"\"\"Returns the path and the Label from the folder\"\"\"\n",
    "    data = load_files(path)\n",
    "    chest_files = np.array(data['filenames'])\n",
    "    chest_targets = np_utils.to_categorical(np.array(data['target']), n_classes)\n",
    "    return chest_files, chest_targets\n",
    "\n",
    "# load list of dog names\n",
    "labels = [item[29:-1] for item in sorted(glob(dest+'/train/*/'))]\n",
    "n_classes = len(labels)\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset(dest+'/train', n_classes)\n",
    "test_files, test_targets = load_dataset(dest+'/test', n_classes)\n",
    "\n",
    "# Img size\n",
    "img_width, img_height, channels = 224, 224, 3\n",
    "\n",
    "#proportions\n",
    "train_prop = np.count_nonzero(train_targets, axis=0) / len(train_targets)\n",
    "test_prop = np.count_nonzero(test_targets, axis=0) / len(test_targets)\n",
    "\n",
    "print('Proportions: \\n')\n",
    "for index, label in enumerate(labels):\n",
    "    print('{} train: {:.4f}'.format(label, train_prop[index]*100))\n",
    "    print('{} test: {:.4f}'.format(label, test_prop[index]*100))\n",
    "    print('*********************')\n",
    "\n",
    "print('\\nStatistics about the Dataset:\\n')\n",
    "print('There are %d total chest deseases.' % len(labels))\n",
    "print('There are %s total chest images.\\n' % len(np.hstack([train_files, test_files])))\n",
    "print('There are %d training chest images.' % len(train_files))\n",
    "print('There are %d test chest images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, channels))\n",
    "model_top = Sequential()\n",
    "\n",
    "model_top.add(Flatten(input_shape=model_cnn.output_shape[1:]))\n",
    "model_top.add(Dense(512))\n",
    "model_top.add(BatchNormalization())\n",
    "model_top.add(Activation('relu'))\n",
    "model_top.add(Dropout(0.25))\n",
    "\n",
    "model_top.add(Dense(n_classes))\n",
    "model_top.add(BatchNormalization())\n",
    "model_top.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model = Model(inputs=model_cnn.input, outputs=model_top(model_cnn.output))\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = os.path.join(IMG_DIR, 'train')\n",
    "validation_data_dir = os.path.join(IMG_DIR, 'test')\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "nb_train_samples = len(train_files) // batch_size\n",
    "nb_validation_samples = len(test_files) // batch_size\n",
    "print('Layers: {}'.format(len(model.layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Layers\n",
    "for layer in model.layers[:310]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Change the learning rate \"\"\"\n",
    "    lrate = 0.001\n",
    "    if epoch > 10:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 30:\n",
    "        lrate = 0.0003\n",
    "    return lrate\n",
    "    \n",
    "# Fit the model    \n",
    "\n",
    "History = model.fit_generator(train_generator, samples_per_epoch=nb_train_samples, epochs=epochs,\n",
    "                    validation_data=validation_generator, nb_val_samples=nb_validation_samples,\n",
    "                   callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,10))  \n",
    "\n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(History.history['acc'])  \n",
    "plt.plot(History.history['val_acc'])  \n",
    "plt.title('Model Accuracy')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "plt.plot(History.history['loss'])  \n",
    "plt.plot(History.history['val_loss'])  \n",
    "plt.title('Model Loss')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions (1)\n",
    "# if you forget to reset the test_generator you will get outputs in a weird order.\n",
    "validation_generator.reset()\n",
    "predictions1 = model.predict_generator(validation_generator, steps=nb_validation_samples)\n",
    "\n",
    "#label with corresponding largest predictied probability\n",
    "predictions1 = np.argmax(predictions1, axis=1)\n",
    "\n",
    "print(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions (3)\n",
    "\n",
    "(eval_loss, eval_accuracy) = model.evaluate_generator(validation_generator,steps = batch_size, verbose=1)\n",
    "\n",
    "print(eval_loss, eval_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(test_targets, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape, predictions1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true[:1632], predictions1, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
