{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from IPython.core.display import Image, display\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras import models, layers, optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "import time\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "# from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions\n",
      "\n",
      "Finding train: 39.8562\n",
      "Finding test: 65.9772\n",
      "Proportions\n",
      "\n",
      "No Finding train: 60.1438\n",
      "No Finding test: 34.0228\n",
      "Statistics about the Dataset:\n",
      "\n",
      "There are 2 total chest deseases.\n",
      "There are 4999 total chest images.\n",
      "\n",
      "There are 4032 training chest images.\n",
      "There are 967 test chest images.\n"
     ]
    }
   ],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    \"\"\"Returns the path and the Label from the folder\"\"\"\n",
    "    data = load_files(path)\n",
    "    chest_files = np.array(data['filenames'])\n",
    "    chest_targets = np_utils.to_categorical(np.array(data['target']), 2)\n",
    "    return chest_files, chest_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('../imgs/images/train')\n",
    "test_files, test_targets = load_dataset('../imgs/images/test')\n",
    "\n",
    "# load list of dog names\n",
    "labels = [item[21:-1] for item in sorted(glob(\"../imgs/images/train/*/\"))]\n",
    "CLASSES = len(labels)\n",
    "\n",
    "#prop\n",
    "train_prop = np.count_nonzero(train_targets, axis=0) / len(train_targets)\n",
    "test_prop = np.count_nonzero(test_targets, axis=0) / len(test_targets)\n",
    "print('Proportions: \\n')\n",
    "for index, label in enumerate(labels):\n",
    "    print('{} train: {:.4f}'.format(label, train_prop[index]*100))\n",
    "    print('{} test: {:.4f}'.format(label, test_prop[index]*100))\n",
    "\n",
    "print('\\nStatistics about the Dataset:\\n')\n",
    "print('There are %d total chest deseases.' % len(labels))\n",
    "print('There are %s total chest images.\\n' % len(np.hstack([train_files, test_files])))\n",
    "print('There are %d training chest images.' % len(train_files))\n",
    "print('There are %d test chest images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding train: 39.8562\n",
      "No Finding train: 60.1438\n"
     ]
    }
   ],
   "source": [
    "prop_label = np.count_nonzero(train_targets, axis=0) / len(train_targets)\n",
    "for index, label in enumerate(labels):\n",
    "    print('{} train: {:.4f}'.format(label, prop_label[index]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6014384920634921"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finding_prop_train, no_finding_prop_train = np.count_nonzero(train_targets, axis=0) / len(train_targets)\n",
    "no_finding_prop_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************TRAIN GENERATOR**********************\n",
      "Found 4032 images belonging to 2 classes.\n",
      "**********************TEST GENERATOR**********************\n",
      "Found 967 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height, channels = 224, 224, 3\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = '../imgs/images/train'\n",
    "test_data_dir = '../imgs/images/test'\n",
    "\n",
    "\n",
    "\n",
    "train_batch_size = 30\n",
    "test_batch_size = 10\n",
    "\n",
    "# ### Load VGG model\n",
    "# model = ResNet50(weights= 'imagenet', include_top=False, input_shape=(img_height, img_width, channels))\n",
    "\n",
    "# ### Freeze some layers\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# ### Check the trainable status of the individual layers\n",
    "# for layer in model.layers:\n",
    "#     print(layer, layer.trainable)\n",
    "\n",
    "print('**********************TRAIN GENERATOR**********************')\n",
    "### Train Generator\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                  samplewise_center=True, \n",
    "                                  samplewise_std_normalization=True, \n",
    "                                  horizontal_flip = True, \n",
    "                                  vertical_flip = False, \n",
    "                                  height_shift_range= 0.05, \n",
    "                                  width_shift_range=0.1, \n",
    "                                  rotation_range=5, \n",
    "                                  shear_range = 0.1,\n",
    "                                  fill_mode = 'reflect',\n",
    "                                  zoom_range=0.15)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size = train_batch_size,\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    shuffle=False)\n",
    "                                                    #color_mode = 'grayscale'\n",
    "    \n",
    "\n",
    "print('**********************TEST GENERATOR**********************')\n",
    "### Test Generator\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=test_batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micka\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 49,279,626\n",
      "Trainable params: 49,225,990\n",
      "Non-trainable params: 53,636\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = 4032\n",
    "nb_test_samples = 967\n",
    "\n",
    "# Define the architecture\n",
    "model = ResNet50(weights= 'imagenet', include_top=False, input_shape=(img_height, img_width, channels)) # or weights=None\n",
    "ChestRESN50_model = Sequential()\n",
    "ChestRESN50_model.add(model)\n",
    "\n",
    "ChestRESN50_model.add(layers.Flatten())\n",
    "\n",
    "ChestRESN50_model.add(layers.Dense(256))\n",
    "ChestRESN50_model.add(layers.BatchNormalization())\n",
    "ChestRESN50_model.add(layers.Activation('relu'))\n",
    "ChestRESN50_model.add(layers.Dropout(0.5))\n",
    "\n",
    "ChestRESN50_model.add(layers.Dense(2))\n",
    "ChestRESN50_model.add(layers.BatchNormalization())\n",
    "ChestRESN50_model.add(layers.Activation('softmax'))\n",
    "ChestRESN50_model.add(layers.Dropout(0.5))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001)\n",
    "ChestRESN50_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "ChestRESN50_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/134 [=====================>........] - ETA: 3:33:22 - loss: 5.2814 - acc: 0.53 - ETA: 3:07:13 - loss: 6.3325 - acc: 0.47 - ETA: 2:59:50 - loss: 6.6986 - acc: 0.45 - ETA: 2:55:54 - loss: 6.4234 - acc: 0.45 - ETA: 2:52:08 - loss: 6.6733 - acc: 0.43 - ETA: 2:51:06 - loss: 6.5800 - acc: 0.43 - ETA: 2:49:13 - loss: 6.7148 - acc: 0.42 - ETA: 2:46:52 - loss: 6.7232 - acc: 0.41 - ETA: 2:45:06 - loss: 6.6014 - acc: 0.42 - ETA: 2:43:13 - loss: 6.4479 - acc: 0.43 - ETA: 2:41:30 - loss: 6.4198 - acc: 0.44 - ETA: 2:39:06 - loss: 6.4405 - acc: 0.43 - ETA: 2:36:50 - loss: 6.3353 - acc: 0.43 - ETA: 2:34:46 - loss: 6.3368 - acc: 0.43 - ETA: 2:33:00 - loss: 6.2982 - acc: 0.43 - ETA: 2:31:09 - loss: 6.3468 - acc: 0.42 - ETA: 2:29:20 - loss: 6.2996 - acc: 0.42 - ETA: 2:27:34 - loss: 6.2232 - acc: 0.43 - ETA: 2:26:17 - loss: 6.2162 - acc: 0.43 - ETA: 2:24:43 - loss: 6.1392 - acc: 0.44 - ETA: 2:23:07 - loss: 6.1283 - acc: 0.43 - ETA: 2:21:33 - loss: 6.0897 - acc: 0.44 - ETA: 2:20:06 - loss: 6.0665 - acc: 0.44 - ETA: 2:18:45 - loss: 6.0007 - acc: 0.44 - ETA: 2:17:22 - loss: 6.0362 - acc: 0.44 - ETA: 2:16:01 - loss: 6.0332 - acc: 0.44 - ETA: 2:14:36 - loss: 6.0332 - acc: 0.44 - ETA: 27:23:51 - loss: 5.9801 - acc: 0.449 - ETA: 26:19:15 - loss: 6.0030 - acc: 0.446 - ETA: 25:18:00 - loss: 5.9964 - acc: 0.447 - ETA: 24:19:50 - loss: 5.9994 - acc: 0.447 - ETA: 23:24:45 - loss: 6.0029 - acc: 0.446 - ETA: 22:32:49 - loss: 5.9722 - acc: 0.444 - ETA: 21:43:49 - loss: 5.9852 - acc: 0.446 - ETA: 20:57:30 - loss: 5.9625 - acc: 0.445 - ETA: 20:13:44 - loss: 5.9628 - acc: 0.444 - ETA: 19:32:11 - loss: 5.9912 - acc: 0.442 - ETA: 18:52:44 - loss: 5.9872 - acc: 0.443 - ETA: 18:15:10 - loss: 5.9959 - acc: 0.444 - ETA: 17:39:25 - loss: 6.0186 - acc: 0.443 - ETA: 17:05:21 - loss: 5.9980 - acc: 0.443 - ETA: 16:32:48 - loss: 5.9672 - acc: 0.444 - ETA: 16:01:47 - loss: 5.9827 - acc: 0.444 - ETA: 15:32:05 - loss: 5.9601 - acc: 0.446 - ETA: 15:03:43 - loss: 5.9397 - acc: 0.447 - ETA: 14:36:31 - loss: 5.9269 - acc: 0.446 - ETA: 14:10:27 - loss: 5.9367 - acc: 0.446 - ETA: 13:45:20 - loss: 5.9187 - acc: 0.447 - ETA: 13:21:10 - loss: 5.9556 - acc: 0.445 - ETA: 12:57:55 - loss: 5.9670 - acc: 0.444 - ETA: 12:35:32 - loss: 5.9548 - acc: 0.445 - ETA: 12:14:01 - loss: 5.9480 - acc: 0.445 - ETA: 11:53:14 - loss: 5.9235 - acc: 0.447 - ETA: 11:58:42 - loss: 5.9113 - acc: 0.448 - ETA: 11:38:35 - loss: 5.9464 - acc: 0.448 - ETA: 11:19:07 - loss: 5.9614 - acc: 0.449 - ETA: 11:00:20 - loss: 5.9959 - acc: 0.448 - ETA: 10:42:12 - loss: 6.0142 - acc: 0.447 - ETA: 10:24:40 - loss: 6.0277 - acc: 0.448 - ETA: 10:07:39 - loss: 6.0277 - acc: 0.449 - ETA: 9:51:10 - loss: 6.0439 - acc: 0.450 - ETA: 9:35:16 - loss: 6.0748 - acc: 0.45 - ETA: 9:19:45 - loss: 6.0828 - acc: 0.44 - ETA: 9:04:40 - loss: 6.1153 - acc: 0.44 - ETA: 8:49:59 - loss: 6.1383 - acc: 0.44 - ETA: 8:35:44 - loss: 6.1606 - acc: 0.44 - ETA: 8:21:49 - loss: 6.1675 - acc: 0.44 - ETA: 8:08:15 - loss: 6.1700 - acc: 0.44 - ETA: 7:55:02 - loss: 6.1903 - acc: 0.44 - ETA: 7:42:11 - loss: 6.1888 - acc: 0.44 - ETA: 7:29:41 - loss: 6.1910 - acc: 0.44 - ETA: 7:17:32 - loss: 6.1968 - acc: 0.44 - ETA: 7:05:41 - loss: 6.2058 - acc: 0.44 - ETA: 6:54:08 - loss: 6.2390 - acc: 0.44 - ETA: 6:42:50 - loss: 6.2722 - acc: 0.44 - ETA: 6:31:49 - loss: 6.2768 - acc: 0.44 - ETA: 6:21:04 - loss: 6.2645 - acc: 0.44 - ETA: 6:10:33 - loss: 6.2750 - acc: 0.44 - ETA: 6:00:15 - loss: 6.2859 - acc: 0.43 - ETA: 5:50:10 - loss: 6.3000 - acc: 0.43 - ETA: 5:40:19 - loss: 6.3070 - acc: 0.43 - ETA: 5:30:40 - loss: 6.3214 - acc: 0.43 - ETA: 5:21:13 - loss: 6.3408 - acc: 0.43 - ETA: 5:11:58 - loss: 6.3493 - acc: 0.43 - ETA: 5:02:53 - loss: 6.3322 - acc: 0.43 - ETA: 4:54:00 - loss: 6.3501 - acc: 0.43 - ETA: 4:45:16 - loss: 6.3627 - acc: 0.43 - ETA: 4:36:42 - loss: 6.3630 - acc: 0.43 - ETA: 4:28:18 - loss: 6.3679 - acc: 0.43 - ETA: 4:20:04 - loss: 6.3564 - acc: 0.43 - ETA: 4:34:26 - loss: 6.3575 - acc: 0.43 - ETA: 4:25:47 - loss: 6.3514 - acc: 0.43 - ETA: 4:17:16 - loss: 6.3540 - acc: 0.43 - ETA: 4:08:53 - loss: 6.3455 - acc: 0.43 - ETA: 4:00:44 - loss: 6.3487 - acc: 0.43 - ETA: 3:52:43 - loss: 6.3427 - acc: 0.43 - ETA: 3:44:51 - loss: 6.3539 - acc: 0.43 - ETA: 3:37:08 - loss: 6.3470 - acc: 0.43 - ETA: 3:29:36 - loss: 6.3574 - acc: 0.43 - ETA: 3:22:13 - loss: 6.3598 - acc: 0.4330"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-48e071f3e398>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                         callbacks=[checkpointer], verbose=1, shuffle=False)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#use_multiprocessing=True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.best.RESN50.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "History = ChestRESN50_model.fit_generator(train_generator, \n",
    "                                        epochs=1,\n",
    "                                        validation_data = test_generator,\n",
    "                                        validation_steps = test_generator.samples / test_generator.batch_size,  \n",
    "                                        steps_per_epoch = train_generator.samples / train_generator.batch_size, \n",
    "                                        callbacks=[checkpointer], verbose=1, shuffle=False)\n",
    "#use_multiprocessing=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model weights with the best validation loss.\n",
    "ChestRes50_model.load_weights('weights.best.RESN50.hdf5')\n",
    "\n",
    "### Calculate classification accuracy on the test dataset.\n",
    "# get index of predicted dog breed for each image in test set\n",
    "predictions = [np.argmax(ChestRes50_model.predict(np.expand_dims(feature, axis=0))) for feature in test_RESNET]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1)[:960])/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(10,10))  \n",
    "\n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(History.history['acc'])  \n",
    "plt.plot(History.history['val_acc'])  \n",
    "plt.title('Model Accuracy')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "plt.plot(History.history['loss'])  \n",
    "plt.plot(History.history['val_loss'])  \n",
    "plt.title('Model Loss')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "y_true = np.argmax(test_targets, axis=1)\n",
    "print(classification_report(y_true[:960], predictions, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
