{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from IPython.core.display import Image, display\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline\n",
    "\n",
    "from keras import models, layers, optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "import time\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "# from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add GPU options\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.333)\n",
    "sess = tf.Session(config = tf.ConfigProto(gpu_options = gpu_options))\n",
    "NAME = 'Binary_chest_cnn_64x3_{}'.format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "#tensorboard --logdir=logs/ --host localhost --port 8088"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics about the Dataset:\n",
      "\n",
      "There are 2 total chest deseases.\n",
      "There are 4999 total chest images.\n",
      "\n",
      "There are 4032 training chest images.\n",
      "There are 967 test chest images.\n"
     ]
    }
   ],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    \"\"\"Returns the path and the Label from the folder\"\"\"\n",
    "    data = load_files(path)\n",
    "    chest_files = np.array(data['filenames'])\n",
    "    chest_targets = np_utils.to_categorical(np.array(data['target']), 2)\n",
    "    return chest_files, chest_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('../imgs/images/train')\n",
    "test_files, test_targets = load_dataset('../imgs/images/test')\n",
    "\n",
    "# load list of dog names\n",
    "labels = [item[21:-1] for item in sorted(glob(\"../imgs/images/train/*/\"))]\n",
    "\n",
    "print('Statistics about the Dataset:\\n')\n",
    "print('There are %d total chest deseases.' % len(labels))\n",
    "print('There are %s total chest images.\\n' % len(np.hstack([train_files, test_files])))\n",
    "print('There are %d training chest images.' % len(train_files))\n",
    "# print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test chest images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4032/4032 [01:24<00:00, 36.69it/s]\n",
      "100%|██████████| 967/967 [00:22<00:00, 42.74it/s]\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4032, 224, 224, 3), (4032, 2))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensors.shape, train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 222, 222, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 109, 109, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 109, 109, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                11944000  \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 11,982,850\n",
      "Trainable params: 11,982,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add( Conv2D(64, (3, 3), input_shape = train_tensors.shape[1:]) )\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# model.add(GlobalAveragePooling2D(input_shape=(train_tensors.shape[1:])))\n",
    "\n",
    "#---------------------------------------\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Activation('softmax'))\n",
    "#----------------------------------------\n",
    "\n",
    "# model.add(layers.Dense(256))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "\n",
    "# model.add(layers.Dense(2))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4032 samples, validate on 967 samples\n",
      "Epoch 1/2\n",
      "4032/4032 [==============================] - ETA: 23:36 - loss: 0.6919 - acc: 0.56 - ETA: 17:59 - loss: 2.8507 - acc: 0.62 - ETA: 15:32 - loss: 4.4052 - acc: 0.59 - ETA: 14:45 - loss: 4.6815 - acc: 0.60 - ETA: 13:59 - loss: 5.0476 - acc: 0.60 - ETA: 13:26 - loss: 5.1248 - acc: 0.61 - ETA: 13:14 - loss: 5.0367 - acc: 0.62 - ETA: 12:52 - loss: 5.2212 - acc: 0.62 - ETA: 13:03 - loss: 5.4760 - acc: 0.61 - ETA: 12:52 - loss: 5.5295 - acc: 0.61 - ETA: 12:35 - loss: 5.6644 - acc: 0.61 - ETA: 12:34 - loss: 5.9020 - acc: 0.59 - ETA: 12:30 - loss: 5.9104 - acc: 0.60 - ETA: 12:40 - loss: 5.8819 - acc: 0.60 - ETA: 12:32 - loss: 5.6233 - acc: 0.62 - ETA: 12:29 - loss: 5.7102 - acc: 0.61 - ETA: 12:20 - loss: 5.7574 - acc: 0.61 - ETA: 12:13 - loss: 5.8271 - acc: 0.61 - ETA: 12:06 - loss: 5.9423 - acc: 0.60 - ETA: 11:55 - loss: 5.9958 - acc: 0.60 - ETA: 11:51 - loss: 6.0204 - acc: 0.60 - ETA: 11:41 - loss: 6.0200 - acc: 0.60 - ETA: 11:34 - loss: 6.0632 - acc: 0.60 - ETA: 11:35 - loss: 6.1237 - acc: 0.60 - ETA: 11:29 - loss: 6.1993 - acc: 0.59 - ETA: 11:24 - loss: 6.1343 - acc: 0.60 - ETA: 11:18 - loss: 6.2039 - acc: 0.59 - ETA: 11:12 - loss: 6.2150 - acc: 0.59 - ETA: 11:05 - loss: 6.2252 - acc: 0.59 - ETA: 11:04 - loss: 6.2181 - acc: 0.59 - ETA: 10:57 - loss: 6.3245 - acc: 0.59 - ETA: 10:57 - loss: 6.3304 - acc: 0.59 - ETA: 10:50 - loss: 6.3663 - acc: 0.59 - ETA: 10:44 - loss: 6.3853 - acc: 0.59 - ETA: 10:39 - loss: 6.4032 - acc: 0.58 - ETA: 10:32 - loss: 6.3506 - acc: 0.59 - ETA: 10:23 - loss: 6.3550 - acc: 0.59 - ETA: 10:13 - loss: 6.3591 - acc: 0.59 - ETA: 10:07 - loss: 6.2860 - acc: 0.59 - ETA: 9:59 - loss: 6.2791 - acc: 0.5984 - ETA: 9:51 - loss: 6.2481 - acc: 0.600 - ETA: 9:44 - loss: 6.2664 - acc: 0.599 - ETA: 9:37 - loss: 6.2604 - acc: 0.600 - ETA: 9:32 - loss: 6.2662 - acc: 0.600 - ETA: 9:24 - loss: 6.2828 - acc: 0.599 - ETA: 9:16 - loss: 6.2986 - acc: 0.598 - ETA: 9:07 - loss: 6.2925 - acc: 0.599 - ETA: 9:00 - loss: 6.2971 - acc: 0.599 - ETA: 8:51 - loss: 6.2810 - acc: 0.600 - ETA: 8:43 - loss: 6.2957 - acc: 0.599 - ETA: 8:36 - loss: 6.3196 - acc: 0.598 - ETA: 8:27 - loss: 6.3329 - acc: 0.597 - ETA: 8:20 - loss: 6.3363 - acc: 0.597 - ETA: 8:12 - loss: 6.3025 - acc: 0.599 - ETA: 8:04 - loss: 6.2698 - acc: 0.601 - ETA: 7:57 - loss: 6.2294 - acc: 0.604 - ETA: 7:49 - loss: 6.2432 - acc: 0.603 - ETA: 7:41 - loss: 6.2737 - acc: 0.601 - ETA: 7:34 - loss: 6.3457 - acc: 0.597 - ETA: 7:25 - loss: 6.2984 - acc: 0.600 - ETA: 7:18 - loss: 6.2937 - acc: 0.600 - ETA: 7:11 - loss: 6.3053 - acc: 0.600 - ETA: 7:03 - loss: 6.3006 - acc: 0.600 - ETA: 6:56 - loss: 6.3509 - acc: 0.597 - ETA: 6:48 - loss: 6.3842 - acc: 0.595 - ETA: 6:41 - loss: 6.3710 - acc: 0.596 - ETA: 6:34 - loss: 6.3432 - acc: 0.598 - ETA: 6:27 - loss: 6.3309 - acc: 0.599 - ETA: 6:20 - loss: 6.3408 - acc: 0.598 - ETA: 6:14 - loss: 6.3075 - acc: 0.600 - ETA: 6:07 - loss: 6.3033 - acc: 0.601 - ETA: 6:00 - loss: 6.3201 - acc: 0.600 - ETA: 5:53 - loss: 6.2884 - acc: 0.602 - ETA: 5:47 - loss: 6.3118 - acc: 0.600 - ETA: 5:40 - loss: 6.3478 - acc: 0.598 - ETA: 5:34 - loss: 6.3368 - acc: 0.599 - ETA: 5:28 - loss: 6.3131 - acc: 0.601 - ETA: 5:21 - loss: 6.3028 - acc: 0.601 - ETA: 5:15 - loss: 6.2864 - acc: 0.602 - ETA: 5:09 - loss: 6.2830 - acc: 0.603 - ETA: 5:03 - loss: 6.2982 - acc: 0.602 - ETA: 4:56 - loss: 6.2703 - acc: 0.604 - ETA: 4:49 - loss: 6.2490 - acc: 0.605 - ETA: 4:43 - loss: 6.2581 - acc: 0.604 - ETA: 4:36 - loss: 6.2729 - acc: 0.604 - ETA: 4:30 - loss: 6.2932 - acc: 0.602 - ETA: 4:23 - loss: 6.3187 - acc: 0.601 - ETA: 4:16 - loss: 6.3095 - acc: 0.601 - ETA: 4:10 - loss: 6.3287 - acc: 0.600 - ETA: 4:03 - loss: 6.3085 - acc: 0.602 - ETA: 3:56 - loss: 6.3327 - acc: 0.600 - ETA: 3:50 - loss: 6.3456 - acc: 0.599 - ETA: 3:43 - loss: 6.3527 - acc: 0.599 - ETA: 3:36 - loss: 6.3331 - acc: 0.600 - ETA: 3:30 - loss: 6.3403 - acc: 0.600 - ETA: 3:23 - loss: 6.3421 - acc: 0.600 - ETA: 3:16 - loss: 6.3438 - acc: 0.600 - ETA: 3:09 - loss: 6.3302 - acc: 0.601 - ETA: 3:02 - loss: 6.3574 - acc: 0.599 - ETA: 2:55 - loss: 6.3589 - acc: 0.599 - ETA: 2:48 - loss: 6.3406 - acc: 0.600 - ETA: 2:42 - loss: 6.3423 - acc: 0.600 - ETA: 2:35 - loss: 6.3536 - acc: 0.599 - ETA: 2:28 - loss: 6.3600 - acc: 0.599 - ETA: 2:21 - loss: 6.3519 - acc: 0.600 - ETA: 2:15 - loss: 6.3723 - acc: 0.598 - ETA: 2:08 - loss: 6.3596 - acc: 0.599 - ETA: 2:01 - loss: 6.3563 - acc: 0.599 - ETA: 1:54 - loss: 6.3394 - acc: 0.600 - ETA: 1:47 - loss: 6.3228 - acc: 0.602 - ETA: 1:41 - loss: 6.3290 - acc: 0.601 - ETA: 1:34 - loss: 6.3351 - acc: 0.601 - ETA: 1:27 - loss: 6.3366 - acc: 0.601 - ETA: 1:20 - loss: 6.3382 - acc: 0.601 - ETA: 1:14 - loss: 6.3310 - acc: 0.601 - ETA: 1:07 - loss: 6.3153 - acc: 0.602 - ETA: 1:00 - loss: 6.3298 - acc: 0.601 - ETA: 54s - loss: 6.3314 - acc: 0.601 - ETA: 47s - loss: 6.3455 - acc: 0.60 - ETA: 40s - loss: 6.3469 - acc: 0.60 - ETA: 33s - loss: 6.3607 - acc: 0.59 - ETA: 27s - loss: 6.3537 - acc: 0.60 - ETA: 20s - loss: 6.3428 - acc: 0.60 - ETA: 13s - loss: 6.3441 - acc: 0.60 - ETA: 6s - loss: 6.3335 - acc: 0.6018 - 928s 230ms/step - loss: 6.3349 - acc: 0.6017 - val_loss: 10.5763 - val_acc: 0.3402\n",
      "Epoch 2/2\n",
      "4032/4032 [==============================] - ETA: 14:24 - loss: 5.0094 - acc: 0.68 - ETA: 14:47 - loss: 5.7609 - acc: 0.64 - ETA: 14:13 - loss: 6.0113 - acc: 0.62 - ETA: 14:03 - loss: 5.8861 - acc: 0.63 - ETA: 13:56 - loss: 6.4121 - acc: 0.60 - ETA: 13:39 - loss: 6.4288 - acc: 0.59 - ETA: 13:35 - loss: 6.1545 - acc: 0.61 - ETA: 13:16 - loss: 6.1992 - acc: 0.61 - ETA: 13:12 - loss: 6.0113 - acc: 0.62 - ETA: 13:05 - loss: 6.2618 - acc: 0.60 - ETA: 12:55 - loss: 6.1480 - acc: 0.61 - ETA: 12:53 - loss: 6.1366 - acc: 0.61 - ETA: 12:39 - loss: 6.2040 - acc: 0.61 - ETA: 12:36 - loss: 6.1545 - acc: 0.61 - ETA: 12:24 - loss: 6.0113 - acc: 0.62 - ETA: 12:49 - loss: 6.1366 - acc: 0.61 - ETA: 13:11 - loss: 6.0703 - acc: 0.62 - ETA: 13:15 - loss: 6.1505 - acc: 0.61 - ETA: 13:19 - loss: 6.0377 - acc: 0.62 - ETA: 13:12 - loss: 6.0865 - acc: 0.62 - ETA: 13:08 - loss: 6.1306 - acc: 0.61 - ETA: 13:06 - loss: 6.1935 - acc: 0.61 - ETA: 13:06 - loss: 6.2074 - acc: 0.61 - ETA: 12:59 - loss: 6.2409 - acc: 0.61 - ETA: 12:54 - loss: 6.2117 - acc: 0.61 - ETA: 12:44 - loss: 6.3003 - acc: 0.60 - ETA: 12:39 - loss: 6.2340 - acc: 0.61 - ETA: 12:30 - loss: 6.2260 - acc: 0.61 - ETA: 12:24 - loss: 6.1668 - acc: 0.61 - ETA: 12:13 - loss: 6.1449 - acc: 0.61 - ETA: 12:03 - loss: 6.1568 - acc: 0.61 - ETA: 11:53 - loss: 6.1679 - acc: 0.61 - ETA: 11:47 - loss: 6.1480 - acc: 0.61 - ETA: 11:42 - loss: 6.1292 - acc: 0.61 - ETA: 11:36 - loss: 6.1402 - acc: 0.61 - ETA: 11:31 - loss: 6.0948 - acc: 0.61 - ETA: 11:26 - loss: 6.1738 - acc: 0.61 - ETA: 11:20 - loss: 6.1564 - acc: 0.61 - ETA: 11:15 - loss: 6.1912 - acc: 0.61 - ETA: 11:08 - loss: 6.1992 - acc: 0.61 - ETA: 11:03 - loss: 6.1824 - acc: 0.61 - ETA: 10:56 - loss: 6.1425 - acc: 0.61 - ETA: 10:51 - loss: 6.1744 - acc: 0.61 - ETA: 10:42 - loss: 6.1707 - acc: 0.61 - ETA: 10:35 - loss: 6.2117 - acc: 0.61 - ETA: 10:28 - loss: 6.1856 - acc: 0.61 - ETA: 10:22 - loss: 6.1712 - acc: 0.61 - ETA: 10:15 - loss: 6.1366 - acc: 0.61 - ETA: 10:10 - loss: 6.1442 - acc: 0.61 - ETA: 10:03 - loss: 6.1516 - acc: 0.61 - ETA: 9:57 - loss: 6.2078 - acc: 0.6127 - ETA: 9:51 - loss: 6.1751 - acc: 0.614 - ETA: 9:43 - loss: 6.2193 - acc: 0.612 - ETA: 9:37 - loss: 6.2154 - acc: 0.612 - ETA: 9:29 - loss: 6.1935 - acc: 0.613 - ETA: 9:23 - loss: 6.1902 - acc: 0.613 - ETA: 9:16 - loss: 6.2047 - acc: 0.612 - ETA: 9:09 - loss: 6.2273 - acc: 0.611 - ETA: 9:01 - loss: 6.2066 - acc: 0.612 - ETA: 8:52 - loss: 6.2201 - acc: 0.612 - ETA: 8:44 - loss: 6.2249 - acc: 0.611 - ETA: 8:36 - loss: 6.2053 - acc: 0.612 - ETA: 8:26 - loss: 6.2181 - acc: 0.612 - ETA: 8:18 - loss: 6.2462 - acc: 0.610 - ETA: 8:10 - loss: 6.2194 - acc: 0.612 - ETA: 8:02 - loss: 6.2163 - acc: 0.612 - ETA: 7:54 - loss: 6.1908 - acc: 0.613 - ETA: 7:47 - loss: 6.1881 - acc: 0.614 - ETA: 7:39 - loss: 6.2001 - acc: 0.613 - ETA: 7:32 - loss: 6.1831 - acc: 0.614 - ETA: 7:24 - loss: 6.2089 - acc: 0.612 - ETA: 7:16 - loss: 6.2062 - acc: 0.612 - ETA: 7:09 - loss: 6.2652 - acc: 0.609 - ETA: 7:01 - loss: 6.3024 - acc: 0.606 - ETA: 6:53 - loss: 6.3186 - acc: 0.605 - ETA: 6:45 - loss: 6.3475 - acc: 0.604 - ETA: 6:38 - loss: 6.3692 - acc: 0.602 - ETA: 6:29 - loss: 6.3646 - acc: 0.603 - ETA: 6:21 - loss: 6.3728 - acc: 0.602 - ETA: 6:12 - loss: 6.3808 - acc: 0.602 - ETA: 6:04 - loss: 6.3577 - acc: 0.603 - ETA: 5:56 - loss: 6.3718 - acc: 0.602 - ETA: 5:47 - loss: 6.3554 - acc: 0.603 - ETA: 5:39 - loss: 6.3274 - acc: 0.605 - ETA: 5:31 - loss: 6.3119 - acc: 0.606 - ETA: 5:22 - loss: 6.3142 - acc: 0.606 - ETA: 5:14 - loss: 6.2935 - acc: 0.607 - ETA: 5:06 - loss: 6.2789 - acc: 0.608 - ETA: 4:58 - loss: 6.2815 - acc: 0.608 - ETA: 4:50 - loss: 6.2729 - acc: 0.608 - ETA: 4:41 - loss: 6.3141 - acc: 0.606 - ETA: 4:33 - loss: 6.3326 - acc: 0.605 - ETA: 4:25 - loss: 6.3453 - acc: 0.604 - ETA: 4:17 - loss: 6.3524 - acc: 0.603 - ETA: 4:09 - loss: 6.3752 - acc: 0.602 - ETA: 4:01 - loss: 6.3923 - acc: 0.601 - ETA: 3:52 - loss: 6.3677 - acc: 0.602 - ETA: 3:44 - loss: 6.3947 - acc: 0.601 - ETA: 3:36 - loss: 6.3858 - acc: 0.601 - ETA: 3:28 - loss: 6.3870 - acc: 0.601 - ETA: 3:20 - loss: 6.3883 - acc: 0.601 - ETA: 3:12 - loss: 6.3993 - acc: 0.600 - ETA: 3:04 - loss: 6.4004 - acc: 0.600 - ETA: 2:56 - loss: 6.3919 - acc: 0.601 - ETA: 2:48 - loss: 6.3978 - acc: 0.600 - ETA: 2:40 - loss: 6.4272 - acc: 0.599 - ETA: 2:32 - loss: 6.4421 - acc: 0.598 - ETA: 2:24 - loss: 6.4566 - acc: 0.597 - ETA: 2:15 - loss: 6.4709 - acc: 0.596 - ETA: 2:07 - loss: 6.4622 - acc: 0.596 - ETA: 1:59 - loss: 6.4581 - acc: 0.597 - ETA: 1:51 - loss: 6.4586 - acc: 0.597 - ETA: 1:43 - loss: 6.4591 - acc: 0.597 - ETA: 1:35 - loss: 6.4683 - acc: 0.596 - ETA: 1:27 - loss: 6.4687 - acc: 0.596 - ETA: 1:19 - loss: 6.4518 - acc: 0.597 - ETA: 1:11 - loss: 6.4652 - acc: 0.596 - ETA: 1:03 - loss: 6.4571 - acc: 0.597 - ETA: 55s - loss: 6.4534 - acc: 0.597 - ETA: 47s - loss: 6.4497 - acc: 0.59 - ETA: 39s - loss: 6.4460 - acc: 0.59 - ETA: 31s - loss: 6.4343 - acc: 0.59 - ETA: 23s - loss: 6.4308 - acc: 0.59 - ETA: 15s - loss: 6.4153 - acc: 0.59 - ETA: 7s - loss: 6.4041 - acc: 0.6005 - 1092s 271ms/step - loss: 6.3890 - acc: 0.6014 - val_loss: 10.5763 - val_acc: 0.3402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x272f040feb8>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(test_tensors, test_targets),\n",
    "          epochs=2, batch_size=32, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 34.0228%\n"
     ]
    }
   ],
   "source": [
    "### Calculate classification accuracy on the test dataset.\n",
    "\n",
    "# get index of predicted dog breed for each image in test set\n",
    "predictions = [np.argmax(model.predict(np.expand_dims(feature, axis=0))) for feature in tqdm(test_tensors)]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3628 samples, validate on 404 samples\n",
      "Epoch 1/2\n",
      "3628/3628 [==============================] - ETA: 14:19 - loss: 4.5085 - acc: 0.71 - ETA: 14:41 - loss: 4.2580 - acc: 0.73 - ETA: 13:49 - loss: 5.3434 - acc: 0.66 - ETA: 14:04 - loss: 5.7609 - acc: 0.64 - ETA: 13:48 - loss: 6.1115 - acc: 0.61 - ETA: 13:45 - loss: 6.0113 - acc: 0.62 - ETA: 13:37 - loss: 6.2976 - acc: 0.60 - ETA: 13:37 - loss: 6.1992 - acc: 0.61 - ETA: 13:25 - loss: 6.2340 - acc: 0.61 - ETA: 13:22 - loss: 6.2618 - acc: 0.60 - ETA: 13:08 - loss: 6.1024 - acc: 0.61 - ETA: 13:07 - loss: 6.0948 - acc: 0.61 - ETA: 12:58 - loss: 6.0113 - acc: 0.62 - ETA: 12:53 - loss: 6.1545 - acc: 0.61 - ETA: 12:41 - loss: 6.1783 - acc: 0.61 - ETA: 12:35 - loss: 6.1992 - acc: 0.61 - ETA: 12:23 - loss: 6.1292 - acc: 0.61 - ETA: 12:18 - loss: 6.2618 - acc: 0.60 - ETA: 12:07 - loss: 6.3014 - acc: 0.60 - ETA: 12:01 - loss: 6.3620 - acc: 0.60 - ETA: 11:54 - loss: 6.3453 - acc: 0.60 - ETA: 11:43 - loss: 6.4440 - acc: 0.59 - ETA: 11:37 - loss: 6.4687 - acc: 0.59 - ETA: 11:28 - loss: 6.5123 - acc: 0.59 - ETA: 11:20 - loss: 6.4722 - acc: 0.59 - ETA: 11:11 - loss: 6.4159 - acc: 0.59 - ETA: 11:05 - loss: 6.4381 - acc: 0.59 - ETA: 10:57 - loss: 6.3513 - acc: 0.60 - ETA: 10:50 - loss: 6.3395 - acc: 0.60 - ETA: 10:41 - loss: 6.3119 - acc: 0.60 - ETA: 10:35 - loss: 6.3022 - acc: 0.60 - ETA: 10:26 - loss: 6.2148 - acc: 0.61 - ETA: 10:20 - loss: 6.1935 - acc: 0.61 - ETA: 10:11 - loss: 6.2323 - acc: 0.61 - ETA: 10:03 - loss: 6.2117 - acc: 0.61 - ETA: 9:54 - loss: 6.2340 - acc: 0.6111 - ETA: 9:47 - loss: 6.2009 - acc: 0.613 - ETA: 9:39 - loss: 6.1432 - acc: 0.616 - ETA: 9:30 - loss: 6.1783 - acc: 0.614 - ETA: 9:22 - loss: 6.2242 - acc: 0.611 - ETA: 9:15 - loss: 6.2679 - acc: 0.609 - ETA: 9:07 - loss: 6.2857 - acc: 0.607 - ETA: 8:59 - loss: 6.3142 - acc: 0.606 - ETA: 8:52 - loss: 6.3301 - acc: 0.605 - ETA: 8:44 - loss: 6.2785 - acc: 0.608 - ETA: 8:35 - loss: 6.2727 - acc: 0.608 - ETA: 8:28 - loss: 6.2458 - acc: 0.610 - ETA: 8:20 - loss: 6.2409 - acc: 0.610 - ETA: 8:12 - loss: 6.3283 - acc: 0.605 - ETA: 8:05 - loss: 6.3219 - acc: 0.605 - ETA: 7:56 - loss: 6.3257 - acc: 0.605 - ETA: 7:49 - loss: 6.3196 - acc: 0.605 - ETA: 7:41 - loss: 6.3138 - acc: 0.606 - ETA: 7:35 - loss: 6.2896 - acc: 0.607 - ETA: 7:26 - loss: 6.2937 - acc: 0.607 - ETA: 7:20 - loss: 6.3244 - acc: 0.605 - ETA: 7:13 - loss: 6.3541 - acc: 0.603 - ETA: 7:08 - loss: 6.3395 - acc: 0.604 - ETA: 7:00 - loss: 6.3595 - acc: 0.603 - ETA: 6:52 - loss: 6.3704 - acc: 0.602 - ETA: 6:44 - loss: 6.3809 - acc: 0.601 - ETA: 6:37 - loss: 6.4072 - acc: 0.600 - ETA: 6:29 - loss: 6.4646 - acc: 0.596 - ETA: 6:22 - loss: 6.4497 - acc: 0.597 - ETA: 6:14 - loss: 6.4352 - acc: 0.598 - ETA: 6:07 - loss: 6.4212 - acc: 0.599 - ETA: 6:00 - loss: 6.4375 - acc: 0.598 - ETA: 5:52 - loss: 6.4534 - acc: 0.597 - ETA: 5:45 - loss: 6.4324 - acc: 0.598 - ETA: 5:38 - loss: 6.4264 - acc: 0.599 - ETA: 5:30 - loss: 6.4206 - acc: 0.599 - ETA: 5:23 - loss: 6.4497 - acc: 0.597 - ETA: 5:15 - loss: 6.4574 - acc: 0.597 - ETA: 5:08 - loss: 6.4649 - acc: 0.596 - ETA: 5:01 - loss: 6.4455 - acc: 0.597 - ETA: 4:53 - loss: 6.4332 - acc: 0.598 - ETA: 4:45 - loss: 6.4082 - acc: 0.600 - ETA: 4:38 - loss: 6.4288 - acc: 0.599 - ETA: 4:30 - loss: 6.4235 - acc: 0.599 - ETA: 4:22 - loss: 6.4121 - acc: 0.600 - ETA: 4:15 - loss: 6.4319 - acc: 0.598 - ETA: 4:07 - loss: 6.4451 - acc: 0.597 - ETA: 3:59 - loss: 6.4218 - acc: 0.599 - ETA: 3:52 - loss: 6.4169 - acc: 0.599 - ETA: 3:44 - loss: 6.4357 - acc: 0.598 - ETA: 3:36 - loss: 6.4540 - acc: 0.597 - ETA: 3:28 - loss: 6.4489 - acc: 0.597 - ETA: 3:20 - loss: 6.4554 - acc: 0.597 - ETA: 3:12 - loss: 6.4504 - acc: 0.597 - ETA: 3:04 - loss: 6.4455 - acc: 0.597 - ETA: 2:57 - loss: 6.4627 - acc: 0.596 - ETA: 2:49 - loss: 6.4687 - acc: 0.596 - ETA: 2:41 - loss: 6.4692 - acc: 0.596 - ETA: 2:33 - loss: 6.4483 - acc: 0.597 - ETA: 2:25 - loss: 6.4754 - acc: 0.596 - ETA: 2:18 - loss: 6.4549 - acc: 0.597 - ETA: 2:10 - loss: 6.4451 - acc: 0.597 - ETA: 2:02 - loss: 6.4305 - acc: 0.598 - ETA: 1:54 - loss: 6.4313 - acc: 0.598 - ETA: 1:46 - loss: 6.4422 - acc: 0.598 - ETA: 1:38 - loss: 6.4180 - acc: 0.599 - ETA: 1:30 - loss: 6.3944 - acc: 0.601 - ETA: 1:22 - loss: 6.3907 - acc: 0.601 - ETA: 1:14 - loss: 6.3919 - acc: 0.601 - ETA: 1:06 - loss: 6.3930 - acc: 0.601 - ETA: 59s - loss: 6.3989 - acc: 0.600 - ETA: 51s - loss: 6.4140 - acc: 0.59 - ETA: 43s - loss: 6.4010 - acc: 0.60 - ETA: 35s - loss: 6.4066 - acc: 0.60 - ETA: 27s - loss: 6.4258 - acc: 0.59 - ETA: 19s - loss: 6.4130 - acc: 0.59 - ETA: 11s - loss: 6.4228 - acc: 0.59 - ETA: 3s - loss: 6.4148 - acc: 0.5998 - 948s 261ms/step - loss: 6.4245 - acc: 0.5992 - val_loss: 6.0709 - val_acc: 0.6213\n",
      "Epoch 2/2\n",
      "3628/3628 [==============================] - ETA: 17:32 - loss: 8.0151 - acc: 0.50 - ETA: 16:01 - loss: 7.5142 - acc: 0.53 - ETA: 16:17 - loss: 6.6793 - acc: 0.58 - ETA: 15:47 - loss: 6.2618 - acc: 0.60 - ETA: 15:42 - loss: 6.6125 - acc: 0.58 - ETA: 15:28 - loss: 6.6793 - acc: 0.58 - ETA: 15:19 - loss: 6.7270 - acc: 0.58 - ETA: 15:06 - loss: 6.7628 - acc: 0.57 - ETA: 14:59 - loss: 6.7906 - acc: 0.57 - ETA: 14:49 - loss: 6.7628 - acc: 0.57 - ETA: 14:39 - loss: 6.8766 - acc: 0.57 - ETA: 14:32 - loss: 6.7628 - acc: 0.57 - ETA: 14:20 - loss: 6.6664 - acc: 0.58 - ETA: 14:12 - loss: 6.5481 - acc: 0.59 - ETA: 14:00 - loss: 6.4121 - acc: 0.60 - ETA: 13:55 - loss: 6.2305 - acc: 0.61 - ETA: 13:41 - loss: 6.2176 - acc: 0.61 - ETA: 13:35 - loss: 6.1505 - acc: 0.61 - ETA: 13:24 - loss: 6.1695 - acc: 0.61 - ETA: 13:20 - loss: 6.2869 - acc: 0.60 - ETA: 13:10 - loss: 6.3214 - acc: 0.60 - ETA: 13:03 - loss: 6.3529 - acc: 0.60 - ETA: 12:53 - loss: 6.3598 - acc: 0.60 - ETA: 12:45 - loss: 6.3453 - acc: 0.60 - ETA: 12:37 - loss: 6.3921 - acc: 0.60 - ETA: 12:28 - loss: 6.3967 - acc: 0.60 - ETA: 12:18 - loss: 6.4010 - acc: 0.60 - ETA: 12:11 - loss: 6.3870 - acc: 0.60 - ETA: 12:03 - loss: 6.3741 - acc: 0.60 - ETA: 11:54 - loss: 6.4455 - acc: 0.59 - ETA: 11:47 - loss: 6.4638 - acc: 0.59 - ETA: 11:38 - loss: 6.4340 - acc: 0.59 - ETA: 11:30 - loss: 6.4060 - acc: 0.60 - ETA: 11:21 - loss: 6.4976 - acc: 0.59 - ETA: 11:13 - loss: 6.4550 - acc: 0.59 - ETA: 11:05 - loss: 6.4984 - acc: 0.59 - ETA: 10:56 - loss: 6.5800 - acc: 0.58 - ETA: 10:48 - loss: 6.5518 - acc: 0.59 - ETA: 10:38 - loss: 6.5765 - acc: 0.58 - ETA: 10:30 - loss: 6.5373 - acc: 0.59 - ETA: 10:21 - loss: 6.5367 - acc: 0.59 - ETA: 10:13 - loss: 6.5123 - acc: 0.59 - ETA: 10:03 - loss: 6.5123 - acc: 0.59 - ETA: 9:56 - loss: 6.5237 - acc: 0.5930 - ETA: 9:47 - loss: 6.5345 - acc: 0.592 - ETA: 9:39 - loss: 6.5450 - acc: 0.591 - ETA: 9:35 - loss: 6.5229 - acc: 0.593 - ETA: 9:24 - loss: 6.4914 - acc: 0.595 - ETA: 9:12 - loss: 6.4612 - acc: 0.596 - ETA: 8:59 - loss: 6.4822 - acc: 0.595 - ETA: 8:47 - loss: 6.4926 - acc: 0.595 - ETA: 8:37 - loss: 6.4738 - acc: 0.596 - ETA: 8:26 - loss: 6.4839 - acc: 0.595 - ETA: 8:15 - loss: 6.4937 - acc: 0.594 - ETA: 8:04 - loss: 6.5214 - acc: 0.593 - ETA: 7:53 - loss: 6.5123 - acc: 0.593 - ETA: 7:42 - loss: 6.5299 - acc: 0.592 - ETA: 7:32 - loss: 6.5296 - acc: 0.592 - ETA: 7:21 - loss: 6.5038 - acc: 0.594 - ETA: 7:11 - loss: 6.5373 - acc: 0.592 - ETA: 7:01 - loss: 6.5369 - acc: 0.592 - ETA: 6:50 - loss: 6.5204 - acc: 0.593 - ETA: 6:41 - loss: 6.5202 - acc: 0.593 - ETA: 6:31 - loss: 6.5279 - acc: 0.592 - ETA: 6:21 - loss: 6.5585 - acc: 0.590 - ETA: 6:12 - loss: 6.5578 - acc: 0.590 - ETA: 6:03 - loss: 6.5347 - acc: 0.592 - ETA: 5:53 - loss: 6.5123 - acc: 0.593 - ETA: 5:44 - loss: 6.5195 - acc: 0.593 - ETA: 5:35 - loss: 6.4908 - acc: 0.595 - ETA: 5:26 - loss: 6.4770 - acc: 0.596 - ETA: 5:18 - loss: 6.4636 - acc: 0.596 - ETA: 5:09 - loss: 6.4574 - acc: 0.597 - ETA: 5:00 - loss: 6.4311 - acc: 0.598 - ETA: 4:52 - loss: 6.4188 - acc: 0.599 - ETA: 4:43 - loss: 6.4266 - acc: 0.599 - ETA: 4:35 - loss: 6.4212 - acc: 0.599 - ETA: 4:26 - loss: 6.3903 - acc: 0.601 - ETA: 4:18 - loss: 6.3855 - acc: 0.601 - ETA: 4:10 - loss: 6.3870 - acc: 0.601 - ETA: 4:02 - loss: 6.3824 - acc: 0.601 - ETA: 3:53 - loss: 6.3779 - acc: 0.602 - ETA: 3:45 - loss: 6.3916 - acc: 0.601 - ETA: 3:37 - loss: 6.3990 - acc: 0.600 - ETA: 3:29 - loss: 6.3826 - acc: 0.601 - ETA: 3:21 - loss: 6.3667 - acc: 0.602 - ETA: 3:14 - loss: 6.3741 - acc: 0.602 - ETA: 3:06 - loss: 6.4098 - acc: 0.600 - ETA: 2:58 - loss: 6.4279 - acc: 0.599 - ETA: 2:50 - loss: 6.4455 - acc: 0.597 - ETA: 2:43 - loss: 6.4297 - acc: 0.598 - ETA: 2:35 - loss: 6.4361 - acc: 0.598 - ETA: 2:28 - loss: 6.4530 - acc: 0.597 - ETA: 2:20 - loss: 6.4590 - acc: 0.597 - ETA: 2:13 - loss: 6.4701 - acc: 0.596 - ETA: 2:05 - loss: 6.4705 - acc: 0.596 - ETA: 1:58 - loss: 6.4606 - acc: 0.597 - ETA: 1:50 - loss: 6.4663 - acc: 0.596 - ETA: 1:43 - loss: 6.4566 - acc: 0.597 - ETA: 1:35 - loss: 6.4772 - acc: 0.595 - ETA: 1:28 - loss: 6.4875 - acc: 0.595 - ETA: 1:21 - loss: 6.4828 - acc: 0.595 - ETA: 1:14 - loss: 6.4685 - acc: 0.596 - ETA: 1:06 - loss: 6.4400 - acc: 0.598 - ETA: 59s - loss: 6.4646 - acc: 0.596 - ETA: 52s - loss: 6.4698 - acc: 0.59 - ETA: 45s - loss: 6.4467 - acc: 0.59 - ETA: 38s - loss: 6.4566 - acc: 0.59 - ETA: 30s - loss: 6.4525 - acc: 0.59 - ETA: 23s - loss: 6.4485 - acc: 0.59 - ETA: 16s - loss: 6.4401 - acc: 0.59 - ETA: 9s - loss: 6.4362 - acc: 0.5985 - ETA: 2s - loss: 6.4325 - acc: 0.598 - 821s 226ms/step - loss: 6.4245 - acc: 0.5992 - val_loss: 6.0709 - val_acc: 0.6213\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "History = model.fit(train_tensors, train_targets, validation_split = 0.1,\n",
    "          epochs=2, batch_size=32, verbose=1, shuffle=True) #callbacks=[tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 967/967 [01:11<00:00, 14.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 34.0228%\n"
     ]
    }
   ],
   "source": [
    "### Calculate classification accuracy on the test dataset.\n",
    "\n",
    "# get index of predicted dog breed for each image in test set\n",
    "predictions = [np.argmax(model.predict(np.expand_dims(feature, axis=0))) for feature in tqdm(test_tensors)]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAJcCAYAAACWv/LQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3X28XWV95/3PlyQQniIhiRoJkqgIilrAI8XBW1ErDbYKHRmNxYqUwlgrKrXe4IytVnHG1untQ4si8uATFCkUoVah6g1iFSwnNaMQYMAAzSFQDiFAoEQC/uaPvQKbw0nOick++6ycz/v12q/sda1rrf1bWQJfr2s9pKqQJElSu2zX7wIkSZK0+QxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJ25wkC5NUkunj6PuOJP88EXVJ0tZkiJPUV0luS/JIkrkj2pc1QWxhfyp7Ui07J3kwybf6XYskbWCIkzQZ3Aq8dcNCkhcDO/avnKc4CvgFcFiS+RP5w+MZTZQ0NRniJE0GXwXe3rV8DPCV7g5JnpbkK0mGk9ye5ENJtmvWTUvyv5Lck2QF8FujbHtWkjuT3JHk1CTTNqO+Y4DTgZ8CR4/Y955J/r6pa3WSv+lad3ySG5KsTbI8yYFNeyV5Xle/LyU5tfl+aJKhJCcnuQs4J8nsJN9sfmNN831B1/a7Jzknyapm/Tea9uuSvKGr34zm72j/zTh2SZOUIU7SZHANMCvJC5pw9RbgayP6/DXwNOA5wKvohL5jm3XHA78NHAAM0Bk56/Zl4FHgeU2fw4A/GE9hSZ4NHAqc23ze3rVuGvBN4HZgIbAHcH6z7r8AH2n6zwLeCKwez28CzwR2B/YCTqDz7+pzmuVnAw8Df9PV/6vATsB+wNOBTzXtXwHe1tXv9cCdVbVsnHVImsQcppc0WWwYjfs+cCNwx4YVXcHugKpaC6xN8lfA7wFnAW8GPl1VK5v+/5NO8CLJM4DDgd2q6mHgoSSfohOOvjCOut4O/LSqlie5D/jLJAdU1U+Ag4BnAR+oqkeb/htukvgD4C+r6tpm+ZbN+Lv4JfDhqvpFs/wwcFHX38fHgSua7/Ob45tTVWuaLt9v/vwa8KdJZlXVA3T+vr66GXVImsQMcZImi68CVwGLGDGVCswFtqcz4rXB7XRGvqATpFaOWLfBXsAM4M4kG9q2G9F/U94OfBGgqlYl+T6d6dWfAHsCt3cFuG57Aj8f52+MNFxV6zYsJNmJzujaYmB207xrE273BO7tCnCPa+r9IfCmJBfTCXvv/RVrkjTJOJ0qaVKoqtvp3ODweuDvR6y+B1hPJ5Bt8GyeGK27k06Y6V63wUo6NyXMrardms+sqtpvrJqS/Cdgb+CDSe5qrlH7deCtzQ0HK4Fnb+Tmg5XAczey6/+gM/25wTNHrK8Ry+8H9gF+vapmAa/cUGLzO7sn2W0jv/VlOlOq/wW4uqru2Eg/SS1jiJM0mRwHvKaqHupurKrHgAuAjyfZNclewB/zxHVzFwDvSbIgyWzglK5t7wT+CfirJLOSbJfkuUleNY56jgG+A7wQ2L/5vIhOADsc+Bc6AfITzWNIZiY5pNn2TOBPkrw0Hc9r6gZYBvxuc0PGYjrX+G3KrnSmVO9Lsjvw4RHH923gc80NEDOSvLJr228AB9IZgRs5wimpxQxxkiaNqvp5VQ1uZPWJwEPACjrXnZ0HnN2s+yJwOfC/gX/lqSN5b6czHbscWANcCGzyUSFJZtK51u6vq+qurs+tdKZ+j2nC5Rvo3DDxb8AQnWv3qKq/Az7e1LmWTpjavdn9e5vt7qNzt+s3NlUL8Gk6j1y5h85NIJeNWP97dEYqbwTuBt63YUVzHeBFdKapR/69SGqxVI0ctZckbUuS/Bnw/Kp625idJbWGNzZI0jasmX49js5onaRtiNOpkrSNSnI8nRsfvl1VV/W7Hklbl9OpkiRJLeRInCRJUgtNiWvi5s6dWwsXLux3GZIkSWNaunTpPVU1b6x+UyLELVy4kMHBjT21QJIkafJIcvvYvZxOlSRJaiVDnCRJUgsZ4iRJklpoSlwTN5r169czNDTEunXr+l1KT82cOZMFCxYwY8aMfpciSZK2oikb4oaGhth1111ZuHAhSfpdTk9UFatXr2ZoaIhFixb1uxxJkrQVTdnp1HXr1jFnzpxtNsABJGHOnDnb/GijJElT0ZQNccA2HeA2mArHKEnSVDSlQ5wkSVJbTdlr4raq+4dg/cObtcl99z/AeRf9A+/6/aM3a7vXL/kDzvvC/8duT5s1/o0evBvO+ZPN+h1JkjTCM18Mh3+i31U8zpG4Prnv/gf43DnnPaX9scce2+R23zr/zM0LcJIkaZvkSNzW8LQFm73JKe/+U35+20r2/43/wowZM9hll12YP38+y5YtY/ny5Rx55JGsXLmSdevW8d73vpcTTjgBeOIVYg8++CCHH344r3jFK/jRj37EHnvswSWXXMKOO+741B8bfhSO/cctPUpJkjSJGOKAP/+H61m+6oGtus8XPmsWH37Dfhtd/4lPfILrrruOZcuWceWVV/Jbv/VbXHfddY8/CuTss89m99135+GHH+ZlL3sZb3rTm5gzZ86T9nHzzTfzt3/7t3zxi1/kzW9+MxdddBFve9vbtupxSJKkyckQN0kcdNBBT3qW22c/+1kuvvhiAFauXMnNN9/8lBC3aNEi9t9/fwBe+tKXctttt01YvZIkqb8McbDJEbOJsvPOOz/+/corr+S73/0uV199NTvttBOHHnroqM9622GHHR7/Pm3aNB5+ePNurpAkSe3ljQ19suuuu7J27dpR191///3Mnj2bnXbaiRtvvJFrrrlmgquTJEmTnSNxfTJnzhwOOeQQXvSiF7HjjjvyjGc84/F1ixcv5vTTT+clL3kJ++yzDwcffHAfK5UkSZNRqqrfNfTcwMBADQ4OPqnthhtu4AUveEGfKppYU+lYJUlquyRLq2pgrH5Op0qSJLWQIU6SJKmFDHGSJEkt1NMQl2RxkpuS3JLklI30eXOS5UmuT3Je07Z/kqubtp8meUtX/0VJfpzk5iRfT7J9L49BkiRpMupZiEsyDTgNOBx4IfDWJC8c0Wdv4IPAIVW1H/C+ZtV/AG9v2hYDn06yW7PuL4BPVdXewBrguF4dgyRJ0mTVy5G4g4BbqmpFVT0CnA8cMaLP8cBpVbUGoKrubv78P1V1c/N9FXA3MC9JgNcAFzbbfxk4sofHIEmSNCn1MsTtAazsWh5q2ro9H3h+kh8muSbJ4pE7SXIQsD3wc2AOcF9VPbqJfW7Y7oQkg0kGh4eHt/BQ+m+XXXbpdwmSJGkS6WWIyyhtIx9KNx3YGzgUeCtwZte0KUnmA18Fjq2qX45zn53GqjOqaqCqBubNm/crlC9JkjR59fKNDUPAnl3LC4BVo/S5pqrWA7cmuYlOqLs2ySzgH4EPVdWG907dA+yWZHozGjfaPlvh5JNPZq+99uJd73oXAB/5yEdIwlVXXcWaNWtYv349p556KkccMXIGWpIkqbch7lpg7ySLgDuAJcDvjujzDTojcF9KMpfO9OqK5o7Ti4GvVNXfbehcVZXkCuAoOtfYHQNcssWVfvsUuOtnW7ybJ3nmi+HwT2x09ZIlS3jf+973eIi74IILuOyyyzjppJOYNWsW99xzDwcffDBvfOMb6VwKKEmS9ISehbiqejTJu4HLgWnA2VV1fZKPAoNVdWmz7rAky4HHgA9U1eokbwNeCcxJ8o5ml++oqmXAycD5SU4FfgKc1atj6KUDDjiAu+++m1WrVjE8PMzs2bOZP38+J510EldddRXbbbcdd9xxB//+7//OM5/5zH6XK0mSJplejsRRVd8CvjWi7c+6vhfwx82nu8/XgK9tZJ8r6Nz5uvVsYsSsl4466iguvPBC7rrrLpYsWcK5557L8PAwS5cuZcaMGSxcuJB169b1pTZJkjS59TTEadOWLFnC8ccfzz333MP3v/99LrjgAp7+9KczY8YMrrjiCm6//fZ+lyhJkiYpQ1wf7bfffqxdu5Y99tiD+fPnc/TRR/OGN7yBgYEB9t9/f/bdd99+lyhJkiYpQ1yf/exnT9xQMXfuXK6++upR+z344IMTVZIkSWqBnr47VZIkSb1hiJMkSWqhKR3iOjfHbtumwjFKkjQVTdkQN3PmTFavXr1Nh5yqYvXq1cycObPfpUiSpK1syt7YsGDBAoaGhhgeHu53KT01c+ZMFixY0O8yJEnSVjZlQ9yMGTNYtGhRv8uQJEn6lUzZ6VRJkqQ2M8RJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRCPQ1xSRYnuSnJLUlO2UifNydZnuT6JOd1tV+W5L4k3xzR/0tJbk2yrPns38tjkCRJmoym92rHSaYBpwGvA4aAa5NcWlXLu/rsDXwQOKSq1iR5etcuPgnsBPzXUXb/gaq6sFe1S5IkTXa9HIk7CLilqlZU1SPA+cARI/ocD5xWVWsAquruDSuq6nvA2h7WJ0mS1Fq9DHF7ACu7loeatm7PB56f5IdJrkmyeJz7/niSnyb5VJIdRuuQ5IQkg0kGh4eHN796SZKkSayXIS6jtNWI5enA3sChwFuBM5PsNsZ+PwjsC7wM2B04ebROVXVGVQ1U1cC8efM2p25JkqRJr5chbgjYs2t5AbBqlD6XVNX6qroVuIlOqNuoqrqzOn4BnENn2laSJGlK6WWIuxbYO8miJNsDS4BLR/T5BvBqgCRz6UyvrtjUTpPMb/4McCRw3VauW5IkadLr2d2pVfVokncDlwPTgLOr6vokHwUGq+rSZt1hSZYDj9G563Q1QJIf0Jk23SXJEHBcVV0OnJtkHp3p2mXAO3t1DJIkSZNVqkZeprbtGRgYqMHBwX6XIUmSNKYkS6tqYKx+vrFBkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWGjPEJXl3ktkTUYwkSZLGZzwjcc8Erk1yQZLFSdLroiRJkrRpY4a4qvoQsDdwFvAO4OYk/yPJc3tcmyRJkjZiXNfEVVUBdzWfR4HZwIVJ/rKHtUmSJGkjpo/VIcl7gGOAe4AzgQ9U1fok2wE3A/9vb0uUJEnSSGOGOGAu8J+r6vbuxqr6ZZLf7k1ZkiRJ2pTxTKd+C7h3w0KSXZP8OkBV3dCrwiRJkrRx4wlxnwce7Fp+qGmTJElSn4wnxKW5sQHoTKMyvmlYSZIk9ch4QtyKJO9JMqP5vBdY0evCJEmStHHjCXHvBP4TcAcwBPw6cEIvi5IkSdKmjTktWlV3A0smoBZJkiSN03ieEzcTOA7YD5i5ob2qfr+HdUmSJGkTxjOd+lU670/9TeD7wAJgbS+LkiRJ0qaNJ8Q9r6r+FHioqr4M/Bbw4t6WJUmSpE0ZT4hb3/x5X5IXAU8DFvasIkmSJI1pPM97OyPJbOBDwKXALsCf9rQqSZIkbdImQ1zzkvsHqmoNcBXwnAmpSpIkSZu0yenU5u0M756gWiRJkjRO47km7jtJ/iTJnkl23/AZz86TLE5yU5JbkpyykT5vTrI8yfVJzutqvyzJfUm+OaL/oiQ/TnJzkq8n2X48tUiSJG1LxnNN3Ibnwf1RV1sxxtRqkmnAacDr6Lzp4dokl1bV8q4+ewMfBA6pqjVJnt61i08COwH/dcSu/wL4VFWdn+R0Os+w+/w4jkOSJGmbMeZIXFUtGuUznmvjDgJuqaoVVfUIcD5wxIg+xwOnNdfcbXg7xIbf/R4jnkeXJMBrgAubpi8DR46jFkmSpG3KeN7Y8PbR2qvqK2Nsugewsmt5w3tXuz2/+Y0fAtOAj1TVZZvY5xzgvqp6tGufe2yk7hNo3vH67Gc/e4xSJUmS2mU806kv6/o+E3gt8K/AWCEuo7TVKL+/N3AonTdB/CDJi6rqvi3YZ6ex6gzgDICBgYFR+0iSJLXVmCGuqk7sXk7yNDqv4hrLELBn1/ICYNUofa6pqvXArUluohPqrt3IPu8BdksyvRmNG22fkiRJ27zx3J060n/QCVpjuRbYu7mbdHtgCZ2HBXf7BvBqgCRz6UyvrtjYDquqgCuAo5qmY4BLNqt6SZKkbcB4ron7B56YstwOeCFwwVjbVdWjSd4NXE7nerezq+r6JB8FBqvq0mbdYUmWA48BH6iq1c3v/gDYF9glyRBwXFVdDpwMnJ/kVOAnwFmbdcSSJEnbgHQGtzbRIXlV1+KjwO1VNdTTqraygYGBGhwc7HcZkiRJY0qytKoGxuo3nhsb/g24s6rWNTveMcnCqrptC2uUJEnSr2g818T9HfDLruXHmjZJkiT1yXhC3PTmYb0ANN991ZUkSVIfjSfEDSd544aFJEfQedSHJEmS+mQ818S9Ezg3yd80y0PAqG9xkCRJ0sQYz8N+fw4cnGQXOnezrh1rG0mSJPXWmNOpSf5Hkt2q6sGqWptkdvOMNkmSJPXJeK6JO7z7XaZVtQZ4fe9KkiRJ0ljGE+KmJdlhw0KSHYEdNtFfkiRJPTaeGxu+BnwvyTnN8rHAl3tXkiRJksYynhsb/jLJT4HfAAJcBuzV68IkSZK0ceOZTgW4i85bG94EvBa4oWcVSZIkaUwbHYlL8nxgCfBWYDXwdTqPGHn1BNUmSZKkjdjUdOqNwA+AN1TVLQBJTpqQqiRJkrRJm5pOfROdadQrknwxyWvpXBMnSZKkPttoiKuqi6vqLcC+wJXAScAzknw+yWETVJ8kSZJGMeaNDVX1UFWdW1W/DSwAlgGn9LwySZIkbdR4704FoKruraovVNVrelWQJEmSxrZZIU6SJEmTgyFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQW6mmIS7I4yU1Jbklyykb6vDnJ8iTXJzmvq/2YJDc3n2O62q9s9rms+Ty9l8cgSZI0GU3v1Y6TTANOA14HDAHXJrm0qpZ39dkb+CBwSFWt2RDIkuwOfBgYAApY2my7ptn06Koa7FXtkiRJk10vR+IOAm6pqhVV9QhwPnDEiD7HA6dtCGdVdXfT/pvAd6rq3mbdd4DFPaxVkiSpVXoZ4vYAVnYtDzVt3Z4PPD/JD5Nck2TxOLc9p5lK/dMkGe3Hk5yQZDDJ4PDw8JYdiSRJ0iTTyxA3WriqEcvTgb2BQ4G3Amcm2W2MbY+uqhcD/0/z+b3RfryqzqiqgaoamDdv3q9QviRJ0uTVyxA3BOzZtbwAWDVKn0uqan1V3QrcRCfUbXTbqrqj+XMtcB6daVtJkqQppZch7lpg7ySLkmwPLAEuHdHnG8CrAZLMpTO9ugK4HDgsyewks4HDgMuTTG/6kWQG8NvAdT08BkmSpEmpZ3enVtWjSd5NJ5BNA86uquuTfBQYrKpLeSKsLQceAz5QVasBknyMThAE+GhV3ZtkZzphbkazz+8CX+zVMUiSJE1WqRp5mdq2Z2BgoAYHfSKJJEma/JIsraqBsfr5xgZJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1UE9DXJLFSW5KckuSUzbS581Jlie5Psl5Xe3HJLm5+RzT1f7SJD9r9vnZJOnlMUiSJE1G03u14yTTgNOA1wFDwLVJLq2q5V199gY+CBxSVWuSPL1p3x34MDAAFLC02XYN8HngBOAa4FvAYuDbvToOSZKkyaiXI3EHAbdU1YqqegQ4HzhiRJ/jgdOacEZV3d20/ybwnaq6t1n3HWBxkvnArKq6uqoK+ApwZA+PQZIkaVLqZYjbA1jZtTzUtHV7PvD8JD9Mck2SxWNsu0fzfVP7BCDJCUkGkwwODw9vwWFIkiRNPr0McaNdq1YjlqcDewOHAm8Fzkyy2ya2Hc8+O41VZ1TVQFUNzJs3b9xFS5IktUEvQ9wQsGfX8gJg1Sh9Lqmq9VV1K3ATnVC3sW2Hmu+b2qckSdI2r5ch7lpg7ySLkmwPLAEuHdHnG8CrAZLMpTO9ugK4HDgsyewks4HDgMur6k5gbZKDm7tS3w5c0sNjkCRJmpR6dndqVT2a5N10Atk04Oyquj7JR4HBqrqUJ8LacuAx4ANVtRogycfoBEGAj1bVvc33PwS+BOxI565U70yVJElTTjo3eW7bBgYGanBwsN9lSJIkjSnJ0qoaGKufb2yQJElqoZ5Np04lf/4P17N81QP9LkOSJPXQC581iw+/Yb9+l/E4R+IkSZJayJG4rWAypXJJkjQ1OBInSZLUQoY4SZKkFjLESZIktZAhTpIkqYUMcZIkSS1kiJMkSWohQ5wkSVILGeIkSZJayBAnSZLUQqmqftfQc0mGgdt7/DNzgXt6/BvafJ6XycdzMjl5XiYfz8nkM1HnZK+qmjdWpykR4iZCksGqGuh3HXoyz8vk4zmZnDwvk4/nZPKZbOfE6VRJkqQWMsRJkiS1kCFu6zmj3wVoVJ6XycdzMjl5XiYfz8nkM6nOidfESZIktZAjcZIkSS1kiJMkSWohQ9xmSrI4yU1Jbklyyijrd0jy9Wb9j5MsnPgqp5ZxnJM/TrI8yU+TfC/JXv2oc6oZ67x09TsqSSWZNLftb6vGc06SvLn55+X6JOdNdI1T0Tj+HfbsJFck+Unz77HX96POqSTJ2UnuTnLdRtYnyWebc/bTJAdOdI1giNssSaYBpwGHAy8E3prkhSO6HQesqarnAZ8C/mJiq5xaxnlOfgIMVNVLgAuBv5zYKqeecZ4XkuwKvAf48cRWOPWM55wk2Rv4IHBIVe0HvG/CC51ixvnPyoeAC6rqAGAJ8LmJrXJK+hKweBPrDwf2bj4nAJ+fgJqewhC3eQ4CbqmqFVX1CHA+cMSIPkcAX26+Xwi8NkkmsMapZsxzUlVXVNV/NIvXAAsmuMapaDz/rAB8jE6oXjeRxU1R4zknxwOnVdUagKq6e4JrnIrGc14KmNV8fxqwagLrm5Kq6irg3k10OQL4SnVcA+yWZP7EVPcEQ9zm2QNY2bU81LSN2qeqHgXuB+ZMSHVT03jOSbfjgG/3tCLBOM5LkgOAPavqmxNZ2BQ2nn9Wng88P8kPk1yTZFMjEdo6xnNePgK8LckQ8C3gxIkpTZuwuf/t6YnpE/2DLTfaiNrIZ7SMp4+2nnH/fSd5GzAAvKqnFQnGOC9JtqNzucE7Jqogjeuflel0pocOpTNi/YMkL6qq+3pc21Q2nvPyVuBLVfVXSV4OfLU5L7/sfXnaiEnx33pH4jbPELBn1/ICnjqs/XifJNPpDH1vakhWW2Y854QkvwH8d+CNVfWLCaptKhvrvOwKvAi4MsltwMHApd7c0FPj/ffXJVW1vqpuBW6iE+rUO+M5L8cBFwBU1dXATDovYlf/jOu/Pb1miNs81wJ7J1mUZHs6F5heOqLPpcAxzfejgP+/fKJyL415Tpppuy/QCXBe4zMxNnlequr+qppbVQuraiGdaxXfWFWD/Sl3ShjPv7++AbwaIMlcOtOrKya0yqlnPOfl34DXAiR5AZ0QNzyhVWqkS4G3N3epHgzcX1V3TnQRTqduhqp6NMm7gcuBacDZVXV9ko8Cg1V1KXAWnaHuW+iMwC3pX8XbvnGek08CuwB/19xj8m9V9ca+FT0FjPO8aAKN85xcDhyWZDnwGPCBqlrdv6q3feM8L+8HvpjkJDpTdu9wcKC3kvwtncsK5jbXIn4YmAFQVafTuTbx9cAtwH8Ax/alTv93IEmS1D5Op0qSJLWQIU6SJKmFDHGSJEktZIiTJElqIUOcJElSCxniJE15SR5Lsqzrc8pW3PfCJNdtrf1J0gY+J06S4OGq2r/fRUjS5nAkTpI2IsltSf4iyb80n+c17Xsl+V6SnzZ/Prtpf0aSi5P87+bzn5pdTUvyxSTXJ/mnJDv27aAkbTMMcZIEO46YTn1L17oHquog4G+ATzdtfwN8papeApwLfLZp/yzw/ar6NeBA4PqmfW/gtKraD7gPeFOPj0fSFOAbGyRNeUkerKpdRmm/DXhNVa1IMgO4q6rmJLkHmF9V65v2O6tqbpJhYEFV/aJrHwuB71TV3s3yycCMqjq190cmaVvmSJwkbVpt5PvG+ozmF13fH8PrkSVtBYY4Sdq0t3T9eXXz/UfAkub70cA/N9+/B/whQJJpSWZNVJGSph7/36AkNdfEdS1fVlUbHjOyQ5If0/k/vW9t2t4DnJ3kA8AwcGzT/l7gjCTH0Rlx+0Pgzp5XL2lK8po4SdqI5pq4gaq6p9+1SNJITqdKkiS1kCNxkiRJLeRInCRJUgsZ4iRJklrIECdJXZoX1leSMe/eT/KOJP88Vj9J6gVDnKSXvGLhAAAdwElEQVTWat5t+kiSuSPalzVBbGF/Ktu8MChJvwpDnKS2u5Unnt9GkhcDvmBe0jbPECep7b4KvL1r+RjgK90dkjwtyVeSDCe5PcmHkmzXrJuW5H8luSfJCuC3Rtn2rCR3JrkjyalJpm1JwUl2SPLpJKuaz6eT7NCsm5vkm0nuS3Jvkh901XpyU8PaJDclee2W1CGp3QxxktruGmBWkhc04eotwNdG9Plr4GnAc4BX0Ql9G96ycDzw28ABwABw1Ihtvww8Cjyv6XMY8AdbWPN/Bw4G9gd+DTgI+FCz7v3AEDAPeAbw34BKsg/wbuBlVbUr8JvAbVtYh6QWM8RJ2hZsGI17HXAjcMeGFV3B7oNVtbaqbgP+Cvi9psubgU9X1cqquhf4n13bPgM4HHhfVT1UVXcDn+KJ96b+qo4GPlpVd1fVMPDnXfWsB+YDe1XV+qr6QXUe6PkYsAPwwiQzquq2qvr5FtYhqcUMcZK2BV8Ffhd4ByOmUoG5wPbA7V1ttwN7NN+fBawcsW6DvYAZwJ3N9OZ9wBeAp29hvc8apZ5nNd8/CdwC/FOSFUlOAaiqW4D3AR8B7k5yfpJnIWnKMsRJar2qup3ODQ6vB/5+xOp76Ixu7dXV9myeGK27E9hzxLoNVgK/AOZW1W7NZ1ZV7beFJa8apZ5VzbGsrar3V9VzgDcAf7zh2reqOq+qXtFsW8BfbGEdklrMECdpW3Ec8Jqqeqi7saoeAy4APp5k1yR7AX/ME9fNXQC8J8mCJLOBU7q2vRP4J+CvksxKsl2S5yZ51WbUtUOSmV2f7YC/BT6UZF7zeJQ/21BPkt9O8rwkAR6gM436WJJ9krymuQFiHfBws07SFGWIk7RNqKqfV9XgRlafCDwErAD+GTgPOLtZ90XgcuB/A//KU0fy3k5nOnY5sAa4kM41a+P1IJ3AteHzGuBUYBD4KfCz5ndPbfrvDXy32e5q4HNVdSWd6+E+QWdk8S46U7r/bTPqkLSNSed6WUmSJLWJI3GSJEktZIiTJElqIUOcJElSCxniJEmSWmh6vwuYCHPnzq2FCxf2uwxJkqQxLV269J6qmjdWvykR4hYuXMjg4MaePCBJkjR5JLl97F5Op0qSJLWSIU6SJKmFDHGSJEktNCWuiRvN+vXrGRoaYt26df0upadmzpzJggULmDFjRr9LkSRJW9GUDXFDQ0PsuuuuLFy4kM57prc9VcXq1asZGhpi0aJF/S5HkiRtRVN2OnXdunXMmTNnmw1wAEmYM2fONj/aKEnSVDRlQxywTQe4DabCMUqSNBVN6RAnSZLUVlP2mritadV9D/Pw+sc2a5sH7r+PSy/6O972+8dv1nbHvfVNfOr0s5j1tN3Gvc3w2l/wkS9cvVm/I0mSnuyFz5rFh9+wX7/LeJwjcX3ywP33c+6XvviU9sce23QYPOtvL9qsACdJkrZNjsQBf/4P17N81QNbdZ9jpfX/fuLHWHnbrbzpda9gxowZ7LLLLsyfP59ly5axfPlyjjzySFauXMm6det473vfywknnAA88QqxBx98kMMPP5xXvOIV/OhHP2KPPfbgkksuYccdd3zKbz1yzw58/b/uv1WPT5Ik9ZcjcX3yiU98guc+97ksW7aMT37yk/zLv/wLH//4x1m+fDkAZ599NkuXLmVwcJDPfvazrF69+in7uPnmm/mjP/ojrr/+enbbbTcuuuiiiT4MSZLUJ47EwaSY3z7ooIOe9Cy3z372s1x88cUArFy5kptvvpk5c+Y8aZtFixax//6dEbaXvvSl3HbbbRNWryRJ6i9D3CSx8847P/79yiuv5Lvf/S5XX301O+20E4ceeuioz3rbYYcdHv8+bdo0Hn744QmpVZIk9Z/TqX2y6667snbt2lHX3X///cyePZuddtqJG2+8kWuuuWaCq5MkSZOdI3F9MmfOHA455BBe9KIXseOOO/KMZzzj8XWLFy/m9NNP5yUveQn77LMPBx98cB8rlSRJk1Gqqt819NzAwEANDg4+qe2GG27gBS94QZ8qmlhT6VglSWq7JEuramCsfk6nSpIktZAhTpIkqYUMcZIkSS1kiJMkSWqhvoS4JLsluTDJjUluSPLyjfR7WZLHkhzV1XZMkpubzzETV7UkSdLk0a9HjHwGuKyqjkqyPbDTyA5JpgF/AVze1bY78GFgAChgaZJLq2rNxJQtSZI0OUz4SFySWcArgbMAquqRqrpvlK4nAhcBd3e1/Sbwnaq6twlu3wEW97jkSWGXXXbpdwmSJGkS6cd06nOAYeCcJD9JcmaSnbs7JNkD+B3g9BHb7gGs7FoeatqeIskJSQaTDA4PD2+96iVJkiaBfkynTgcOBE6sqh8n+QxwCvCnXX0+DZxcVY8l6d72SQuNUZ9WXFVnAGdA52G/m6zo26fAXT8b9wGMyzNfDId/YqOrTz75ZPbaay/e9a53AfCRj3yEJFx11VWsWbOG9evXc+qpp3LEEUds3bokSdI2oR8jcUPAUFX9uFm+kE6o6zYAnJ/kNuAo4HNJjmy23bOr3wJgVW/L7Y0lS5bw9a9//fHlCy64gGOPPZaLL76Yf/3Xf+WKK67g/e9/P1PhjRqSJGnzTfhIXFXdlWRlkn2q6ibgtcDyEX0Wbfie5EvAN6vqG82NDf8jyexm9WHAB7e4qE2MmPXKAQccwN13382qVasYHh5m9uzZzJ8/n5NOOomrrrqK7bbbjjvuuIN///d/55nPfOaE1ydJkia3ft2deiJwbnNn6grg2CTvBKiqkdfBPa6q7k3yMeDapumjVXVvz6vtkaOOOooLL7yQu+66iyVLlnDuuecyPDzM0qVLmTFjBgsXLmTdunX9LlOSJE1CfQlxVbWMzpRpt1HDW1W9Y8Ty2cDZvalsYi1ZsoTjjz+ee+65h+9///tccMEFPP3pT2fGjBlcccUV3H777f0uUZIkTVL9GokTsN9++7F27Vr22GMP5s+fz9FHH80b3vAGBgYG2H///dl33337XaIkSZqkDHF99rOfPXFX7Ny5c7n66qtH7ffggw9OVEmSJKkFfHeqJElSCxniJEmSWmhKh7ip8Ay2qXCMkiRNRVM2xM2cOZPVq1dv0yGnqli9ejUzZ87sdymSJGkrm7I3NixYsIChoSG29feqzpw5kwULFvS7DEmStJVN2RA3Y8YMFi1aNHZHSZKkSWjKTqdKkiS1mSFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRCfQlxSXZLcmGSG5PckOTlI9YfkeSnSZYlGUzyiq51jzXty5JcOvHVS5Ik9d/0Pv3uZ4DLquqoJNsDO41Y/z3g0qqqJC8BLgD2bdY9XFX7T2CtkiRJk86Eh7gks4BXAu8AqKpHgEe6+1TVg12LOwM1UfVJkiS1QT+mU58DDAPnJPlJkjOT7DyyU5LfSXIj8I/A73etmtlMsV6T5MiN/UiSE5p+g8PDw1v9ICRJkvqpHyFuOnAg8PmqOgB4CDhlZKequriq9gWOBD7WterZVTUA/C7w6STPHe1HquqMqhqoqoF58+Zt9YOQJEnqp36EuCFgqKp+3CxfSCfUjaqqrgKem2Rus7yq+XMFcCVwQE+rlSRJmoQmPMRV1V3AyiT7NE2vBZZ390nyvCRpvh8IbA+sTjI7yQ5N+1zgkJHbSpIkTQX9ujv1RODc5s7UFcCxSd4JUFWnA28C3p5kPfAw8JbmTtUXAF9I8ks6AfQTVWWIkyRJU06qtv0bPwcGBmpwcLDfZUiSJI0pydLm+v9N8o0NkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1UF9CXJLdklyY5MYkNyR5+Yj1RyT5aZJlSQaTvKJr3TFJbm4+x0x89ZIkSf03vU+/+xngsqo6Ksn2wE4j1n8PuLSqKslLgAuAfZPsDnwYGAAKWJrk0qpaM5HFS5Ik9duEj8QlmQW8EjgLoKoeqar7uvtU1YNVVc3iznQCG8BvAt+pqnub4PYdYPHEVC5JkjR59GM69TnAMHBOkp8kOTPJziM7JfmdJDcC/wj8ftO8B7Cyq9tQ0/YUSU5opmIHh4eHt+4RSJIk9Vk/Qtx04EDg81V1APAQcMrITlV1cVXtCxwJfKxpzij7q1HaqKozqmqgqgbmzZu3dSqXJEmaJPoR4oaAoar6cbN8IZ1QN6qqugp4bpK5zbZ7dq1eAKzqVaGSJEmT1YSHuKq6C1iZZJ+m6bXA8u4+SZ6XJM33A4HtgdXA5cBhSWYnmQ0c1rRJkiRNKf26O/VE4NzmztQVwLFJ3glQVacDbwLenmQ98DDwluZGh3uTfAy4ttnPR6vq3okvX5Ikqb/yxE2g266BgYEaHBzsdxmSJEljSrK0qgbG6ucbGyRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQWMsRJkiS1kCFOkiSphQxxkiRJLWSIkyRJaiFDnCRJUgsZ4iRJklrIECdJktRChjhJkqQW2qIQl+S5SXZovh+a5D1Jdts6pUmSJGljtnQk7iLgsSTPA84CFgHnbXFVkiRJ2qQtDXG/rKpHgd8BPl1VJwHzt7wsSZIkbcqWhrj1Sd4KHAN8s2mbsYX7lCRJ0hi2NMQdC7wc+HhV3ZpkEfC1sTZKsluSC5PcmOSGJC8fsf7oJD9tPj9K8mtd625L8rMky5IMbmH9kiRJrTR9SzauquXAewCSzAZ2rapPjGPTzwCXVdVRSbYHdhqx/lbgVVW1JsnhwBnAr3etf3VV3bMltUuSJLXZFoW4JFcCb2z2swwYTvL9qvrjTWwzC3gl8A6AqnoEeKS7T1X9qGvxGmDBltQpSZK0rdnS6dSnVdUDwH8GzqmqlwK/McY2zwGGgXOS/CTJmUl23kT/44Bvdy0X8E9JliY5YWMbJTkhyWCSweHh4fEdjSRJUktsaYibnmQ+8GaeuLFhzG2AA4HPV9UBwEPAKaN1TPJqOiHu5K7mQ6rqQOBw4I+SvHK0bavqjKoaqKqBefPmjbM0SZKkdtjSEPdR4HLg51V1bZLnADePsc0QMFRVP26WL6QT6p4kyUuAM4Ejqmr1hvaqWtX8eTdwMXDQFh6DJElS62xRiKuqv6uql1TVHzbLK6rqTWNscxewMsk+TdNrgeXdfZI8G/h74Peq6v90te+cZNcN34HDgOu25BgkSZLaaEtvbFgA/DVwCJ1r1f4ZeG9VDY2x6YnAuc2dqSuAY5O8E6CqTgf+DJgDfC4JwKNVNQA8A7i4aZsOnFdVl23JMUiSJLVRqupX3zj5Dp3XbH21aXobcHRVvW4r1LbVDAwM1OCgj5STJEmTX5KlzeDVJm3pNXHzquqcqnq0+XwJ8C4CSZKkHtvSEHdPkrclmdZ83gasHnMrSZIkbZEtDXG/T+fxIncBdwJH0XkVlyRJknpoS+9O/beqemNVzauqp1fVkXQe/CtJkqQe2tKRuNFs9JVbkiRJ2jp6EeLSg31KkiSpSy9C3K/+zBJJkiSNy6/0sN8kaxk9rAXYcYsqkiRJ0ph+pRBXVbtu7UIkSZI0fr2YTpUkSVKPGeIkSZJayBAnSZLUQoY4SZKkFjLESZIktZAhTpIkqYUMcZIkSS1kiJMkSWohQ5wkSVILGeIkSZJayBAnSZLUQoY4SZKkFjLESZIktZAhTpIkqYX6EuKS7JbkwiQ3JrkhyctHrD86yU+bz4+S/FrXusVJbkpyS5JTJr56SZKk/pvep9/9DHBZVR2VZHtgpxHrbwVeVVVrkhwOnAH8epJpwGnA64Ah4Nokl1bV8oksXpIkqd8mfCQuySzglcBZAFX1SFXd192nqn5UVWuaxWuABc33g4BbqmpFVT0CnA8cMTGVS5IkTR79mE59DjAMnJPkJ0nOTLLzJvofB3y7+b4HsLJr3VDT9hRJTkgymGRweHh4a9QtSZI0afQjxE0HDgQ+X1UHAA8Bo17bluTVdELcyRuaRulWo21bVWdU1UBVDcybN2/Lq5YkSZpE+hHihoChqvpxs3whnVD3JEleApwJHFFVq7u23bOr2wJgVQ9rlSRJmpQmPMRV1V3AyiT7NE2vBZ50Y0KSZwN/D/xeVf2frlXXAnsnWdTcELEEuHQCypYkSZpU+nV36onAuU0QWwEcm+SdAFV1OvBnwBzgc0kAHm2mRh9N8m7gcmAacHZVXd+XI5AkSeqjVI16Sdk2ZWBgoAYHB/tdhiRJ0piSLK2qgbH6+cYGSZKkFjLESZIktZAhTpIkqYUMcZIkSS1kiJMkSWohQ5wkSVILGeIkSZJayBAnSZLUQoY4SZKkFjLESZIktZAhTpIkqYUMcZIkSS1kiJMkSWohQ5wkSVILGeIkSZJayBAnSZLUQoY4SZKkFjLESZIktZAhTpIkqYUMcZIkSS1kiJMkSWohQ5wkSVIL9SXEJdktyYVJbkxyQ5KXj1i/b5Krk/wiyZ+MWHdbkp8lWZZkcGIrlyRJmhym9+l3PwNcVlVHJdke2GnE+nuB9wBHbmT7V1fVPb0sUJIkaTKb8JG4JLOAVwJnAVTVI1V1X3efqrq7qq4F1k90fZIkSW3Qj+nU5wDDwDlJfpLkzCQ7b8b2BfxTkqVJTthYpyQnJBlMMjg8PLylNUuSJE0q/Qhx04EDgc9X1QHAQ8Apm7H9IVV1IHA48EdJXjlap6o6o6oGqmpg3rx5W1y0JEnSZNKPEDcEDFXVj5vlC+mEunGpqlXNn3cDFwMHbfUKJUmSJrkJD3FVdRewMsk+TdNrgeXj2TbJzkl23fAdOAy4rieFSpIkTWL9ujv1RODc5s7UFcCxSd4JUFWnJ3kmMAjMAn6Z5H3AC4G5wMVJoFP7eVV1WT8OQJIkqZ/6EuKqahkwMKL59K71dwELRtn0AeDXeliaJElSK/jGBv3f9u4+VLK6juP4+9OumqUmuJLiqmu4VmqWsogW9GSF+ocGSSpJKZIkqNmDZBQU1R9ZRCWapmlmWGYL1RI+FGbParugmWsJy2a6qLjmE2X5+O2POdrtend3bu6cmd/O+wXDPed3zsx8Z787M5/7O2fmSpKkBhniJEmSGmSIkyRJapAhTpIkqUGGOEmSpAYZ4iRJkhpkiJMkSWqQIU6SJKlBhjhJkqQGGeIkSZIaZIiTJElqkCFOkiSpQYY4SZKkBhniJEmSGmSIkyRJapAhTpIkqUGGOEmSpAYZ4iRJkhpkiJMkSWqQIU6SJKlBhjhJkqQGGeIkSZIaZIiTJElq0FhCXJIdkyxP8pckf05y6Kztr0lyY5Inknx81rbDk9yZZE2Ss/utXJIkaTIsHNP9fh24tqqOSbI18LJZ2x8CzgDePXMwyQLgfOCdwDpgZZIVVXVHDzVLkiRNjN5n4pLsALwZuASgqp6sqkdm7lNVD1TVSuCpWVc/GFhTVWur6kngSuDoHsqWJEmaKOM4nPoqYD3w7SS3JPlWkpcPed3dgHtmrK/rxl4gySlJViVZtX79+hdXsSRJ0oQZR4hbCBwEXFBVBwL/BIY9ty1zjNVcO1bVRVW1rKqW7bzzzv9fpZIkSRNqHCFuHbCuqm7u1pczCHXDXnf3GeuLgXs3Y22SJElN6D3EVdX9wD1JXt0NHQYM+8GElcDSJHt1H4g4DlgxgjIlSZIm2rg+nXo6cEUXxNYCJyX5EEBVXZhkF2AVsAPwbJIzgX2r6rEkpwHXAQuAS6tq9XgegiRJ0viMJcRV1a3AslnDF87Yfj+DQ6VzXfdq4OrRVSdJkjT5/IsNkiRJDTLESZIkNcgQJ0mS1CBDnCRJUoMMcZIkSQ0yxEmSJDXIECdJktQgQ5wkSVKDDHGSJEkNMsRJkiQ1yBAnSZLUIEOcJElSgxaOu4AtwjVnw/1/GncVkiRplHZ5HRzxxXFX8Txn4iRJkhrkTNzmMEGpXJIkTQdn4iRJkhpkiJMkSWqQIU6SJKlBhjhJkqQGGeIkSZIaZIiTJElqkCFOkiSpQYY4SZKkBhniJEmSGpSqGncNI5dkPfC3Ed/NIuDBEd+H5s++TB57Mpnsy+SxJ5Onr57sWVU7b2qnqQhxfUiyqqqWjbsO/S/7MnnsyWSyL5PHnkyeSeuJh1MlSZIaZIiTJElqkCFu87lo3AVoTvZl8tiTyWRfJo89mTwT1RPPiZMkSWqQM3GSJEkNMsRJkiQ1yBA3T0kOT3JnkjVJzp5j+zZJftBtvznJkv6rnC5D9OSjSe5IcluS65PsOY46p82m+jJjv2OSVJKJ+dj+lmqYniR5b/d8WZ3ke33XOI2GeA3bI8kNSW7pXseOHEed0yTJpUkeSHL7BrYnybldz25LclDfNYIhbl6SLADOB44A9gWOT7LvrN1OBh6uqr2BrwLn9FvldBmyJ7cAy6rqAGA58KV+q5w+Q/aFJNsDZwA391vh9BmmJ0mWAp8E3lRV+wFn9l7olBnyufJp4KqqOhA4DvhGv1VOpcuAwzey/QhgaXc5Bbigh5pewBA3PwcDa6pqbVU9CVwJHD1rn6OB73TLy4HDkqTHGqfNJntSVTdU1ePd6k3A4p5rnEbDPFcAPs8gVP+7z+Km1DA9+SBwflU9DFBVD/Rc4zQapi8F7NAtvwK4t8f6plJV/Rp4aCO7HA1cXgM3ATsm2bWf6v7LEDc/uwH3zFhf143NuU9VPQ08CuzUS3XTaZiezHQycM1IKxIM0ZckBwK7V9VP+yxsig3zXNkH2CfJ75LclGRjMxHaPIbpy2eBE5KsA64GTu+nNG3EfN97RmJh33fYuLlm1GZ/R8sw+2jzGfrfO8kJwDLgLSOtSLCJviR5CYPTDU7sqyAN9VxZyODw0FsZzFj/Jsn+VfXIiGubZsP05Xjgsqr6SpJDge92fXl29OVpAybivd6ZuPlZB+w+Y30xL5zWfn6fJAsZTH1vbEpWL84wPSHJO4BPAUdV1RM91TbNNtWX7YH9gV8muQs4BFjhhxtGatjXr59U1VNV9VfgTgahTqMzTF9OBq4CqKobgZcy+EPsGp+h3ntGzRA3PyuBpUn2SrI1gxNMV8zaZwXwgW75GOAX5Tcqj9Ime9IdtvsmgwDnOT792GhfqurRqlpUVUuqagmDcxWPqqpV4yl3Kgzz+vVj4G0ASRYxOLy6ttcqp88wfbkbOAwgyWsZhLj1vVap2VYA7+8+pXoI8GhV3dd3ER5OnYeqejrJacB1wALg0qpaneRzwKqqWgFcwmCqew2DGbjjxlfxlm/InnwZ2A74YfcZk7ur6qixFT0FhuyLejRkT64D3pXkDuAZ4Kyq+vv4qt7yDdmXjwEXJ/kIg0N2Jzo5MFpJvs/gtIJF3bmInwG2AqiqCxmcm3gksAZ4HDhpLHX6/0CSJKk9Hk6VJElqkCFOkiSpQYY4SZKkBhniJEmSGmSIkyRJapAhTtLUS/JMkltnXM7ejLe9JMntm+v2JOk5fk+cJMG/quoN4y5CkubDmThJ2oAkdyU5J8kfusve3fieSa5Pclv3c49u/JVJfpTkj93ljd1NLUhycZLVSX6WZNuxPShJWwxDnCTBtrMOpx47Y9tjVXUwcB7wtW7sPODyqjoAuAI4txs/F/hVVb0eOAhY3Y0vBc6vqv2AR4D3jPjxSJoC/sUGSVMvyT+qars5xu8C3l5Va5NsBdxfVTsleRDYtaqe6sbvq6pFSdYDi6vqiRm3sQT4eVUt7dY/AWxVVV8Y/SOTtCVzJk6SNq42sLyhfebyxIzlZ/B8ZEmbgSFOkjbu2Bk/b+yWfw8c1y2/D/htt3w9cCpAkgVJduirSEnTx98GJak7J27G+rVV9dzXjGyT5GYGv/Qe342dAVya5CxgPXBSN/5h4KIkJzOYcTsVuG/k1UuaSp4TJ0kb0J0Tt6yqHhx3LZI0m4dTJUmSGuRMnCRJUoOciZMkSWqQIU6SJKlBhjhJkqQGGeIkSZIaZIiTJElq0H8Ab8l2gjUuX+MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(10,10))  \n",
    "\n",
    "# summarize history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(History.history['acc'])  \n",
    "plt.plot(History.history['val_acc'])  \n",
    "plt.title('Model Accuracy')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')  \n",
    "\n",
    "# summarize history for loss  \n",
    "\n",
    "plt.subplot(212)  \n",
    "plt.plot(History.history['loss'])  \n",
    "plt.plot(History.history['val_loss'])  \n",
    "plt.title('Model Loss')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'val'], loc='upper left')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [6.0708578600741845, 6.0708578600741845],\n",
       " 'val_acc': [0.6212871287128713, 0.6212871287128713],\n",
       " 'loss': [6.424467478986612, 6.42446746006033],\n",
       " 'acc': [0.5992282248844517, 0.5992282249173098]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "History.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
