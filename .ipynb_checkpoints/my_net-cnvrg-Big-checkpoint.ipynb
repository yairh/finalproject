{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T17:12:02.250633Z",
     "start_time": "2019-01-09T17:11:39.401674Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from class_dataset import ChestDataset\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications\n",
    "from keras.applications import DenseNet121\n",
    "from keras import models\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chown -R ds:ds /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T17:12:04.265498Z",
     "start_time": "2019-01-09T17:12:04.148181Z"
    }
   },
   "outputs": [],
   "source": [
    "csvfile = 'data_kaggle/Data_Entry_2017.csv'\n",
    "df = pd.read_csv(csvfile)\n",
    "\n",
    "data_dir = '/data/xray_chest_final/'\n",
    "\n",
    "ChestDataset(data_dir,df).reset_folder()\n",
    "\n",
    "df_uni = ChestDataset(data_dir,df[~df['Finding Labels'].str.contains('\\|')]).reader\n",
    "df_uni = df_uni[df_uni.exists == True]\n",
    "\n",
    "df_rd = df_uni.groupby('Finding Labels',group_keys=False).apply(lambda df: df.sample(67))\n",
    "\n",
    "dataset = ChestDataset(data_dir,df_rd)\n",
    "\n",
    "train_list = [el[16:] for i,el in enumerate(dataset.image_path) if not i%3 == 0]\n",
    "test_list = [el[16:] for i,el in enumerate(dataset.image_path) if i%3 == 0]\n",
    "\n",
    "with open('dense_train_list.txt', 'w') as f:\n",
    "    for item in train_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open('dense_test_list.txt', 'w') as f:\n",
    "    for item in test_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "# train_dt,test_dt = dataset.train_test(train_list,test_list)\n",
    "# train_dt.create_tree()\n",
    "# test_dt.create_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T17:12:10.942249Z",
     "start_time": "2019-01-09T17:12:10.936160Z"
    }
   },
   "outputs": [],
   "source": [
    "train_files = train_dt.image_path\n",
    "test_files = test_dt.image_path\n",
    "train_folder = train_dt.dir\n",
    "test_folder = test_dt.dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T17:12:11.516058Z",
     "start_time": "2019-01-09T17:12:11.503009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train # No Finding: 0.7090673094752457\n",
      "Test # No Finding: 0.5034446210916799\n"
     ]
    }
   ],
   "source": [
    "label_train = [train_dt.labels[i] for i, el in enumerate(train_dt.exists) if el == True]\n",
    "label_test = [test_dt.labels[i] for i, el in enumerate(test_dt.exists) if el == True]\n",
    "print('Train # No Finding:',label_train.count('No Finding')/len(label_train))\n",
    "print('Test # No Finding:',label_test.count('No Finding')/len(label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T17:12:12.132212Z",
     "start_time": "2019-01-09T17:12:12.106764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics about the Dataset:\n",
      "\n",
      "There are 15 total chest deseases.\n",
      "There are 12673 total chest images.\n",
      "\n",
      "There are 10786 training chest images.\n",
      "There are 1887 test chest images.\n",
      "# of Infiltration: 8.672%\n",
      "# of Mass: 1.941%\n",
      "# of Effusion: 3.803%\n",
      "# of Hernia: 0.221%\n",
      "# of Fibrosis: 1.452%\n",
      "# of Emphysema: 0.955%\n",
      "# of Pneumothorax: 1.712%\n",
      "# of Consolidation: 1.499%\n",
      "# of Pneumonia: 0.308%\n",
      "# of Atelectasis: 4.569%\n",
      "# of Pleural_Thickening: 1.278%\n",
      "# of Edema: 0.529%\n",
      "# of No Finding: 67.845%\n",
      "# of Nodule: 3.133%\n",
      "# of Cardiomegaly: 2.083%\n"
     ]
    }
   ],
   "source": [
    "labels = set(dataset.labels)\n",
    "print('Statistics about the Dataset:\\n')\n",
    "print('There are %d total chest deseases.' % len(set(dataset.labels)))\n",
    "print('There are %s total chest images.\\n' % np.sum(dataset.exists))\n",
    "print('There are %d training chest images.' % np.sum(train_dt.exists))\n",
    "# print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test chest images.'% np.sum(test_dt.exists))\n",
    "for lab in labels:\n",
    "    print('# of %s: %.3f%%'%(lab,100*dataset.labels.count(lab)/len(dataset.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T17:12:52.086479Z",
     "start_time": "2019-01-09T17:12:15.791713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 11, 11, 1024)      7037504   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 123904)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                1858575   \n",
      "=================================================================\n",
      "Total params: 8,896,079\n",
      "Trainable params: 1,858,575\n",
      "Non-trainable params: 7,037,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_width,img_height = 365,365\n",
    "densenet = DenseNet121(weights='imagenet', include_top=False,input_shape = (img_width, img_height, 3))\n",
    "\n",
    "# # Freeze some layers\n",
    "# for layer in densenet.layers[:]:\n",
    "#     layer.trainable = False\n",
    "    \n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the vgg convolutional base model\n",
    "\n",
    "model.add(densenet)\n",
    "\n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(72))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.248))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-09T17:13:11.789Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 10\n",
    "val_batchsize = 10\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_folder,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=train_batchsize,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    test_folder,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=val_batchsize,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=2,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_generator(validation_generator,\n",
    "                                     steps=len(validation_generator),\n",
    "                                     pickle_safe=True,\n",
    "                                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(prediction,axis=1)\n",
    "print(preds.shape)\n",
    "\n",
    "y_true = np.zeros((preds.shape[0],validation_generator.num_classes))\n",
    "y_true[np.arange(preds.shape[0]), validation_generator.classes] = 1\n",
    "inv_map = {v:k for k,v in validation_generator.class_indices.items()}\n",
    "pred_cat = [inv_map[i] for i in preds]\n",
    "\n",
    "print(classification_report(validation_generator.classes,preds))\n",
    "print('Accuracy score: ',accuracy_score(validation_generator.classes,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator,\n",
    "                                 steps=len(validation_generator),\n",
    "                                 pickle_safe=True,\n",
    "                                 verbose=1)\n",
    "print('Accuracy Keras: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auc scores\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(validation_generator.num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], prediction[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for i in range(validation_generator.num_classes):\n",
    "    plt.plot(fpr[i], tpr[i],\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(inv_map[i], roc_auc[i]))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
